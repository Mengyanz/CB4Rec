{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import copy\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "from datetime import datetime \n",
    "import math\n",
    "import uncertainty_toolbox as utc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'small/'\n",
    "\n",
    "data_path = Path(\"/home/v-mezhang/blob-plm/data/\" + str(dataset) + \"utils/\")\n",
    "model_path = Path(\"/home/v-mezhang/blob-plm/model/\" + str(dataset))\n",
    "\n",
    "date_format_str = '%m/%d/%Y %I:%M:%S %p'\n",
    "\n",
    "# sys.stdout = open(model_path / 'output.txt', \"w\")\n",
    "# print(model_path)\n",
    "# sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "npratio = 4\n",
    "max_his_len = 50\n",
    "min_word_cnt = 3\n",
    "max_title_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch = 5\n",
    "lr=0.0001\n",
    "name = 'nrms_' + dataset[:-1]\n",
    "retrain = False\n",
    "online_flag = False\n",
    "offline_flag = False\n",
    "cb_flag = False\n",
    "eva_times = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'train_sam_uid.pkl', 'rb') as f:\n",
    "    train_sam = pickle.load(f)\n",
    "\n",
    "with open(data_path/'sorted_train_sam_uid.pkl', 'rb') as f:\n",
    "    sorted_train_sam = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'sorted_valid_sam_uid.pkl', 'rb') as f:\n",
    "    valid_sam = pickle.load(f)\n",
    "\n",
    "if os.path.exists(data_path/'test_sam_uid.pkl'):    \n",
    "    with open(data_path/'test_sam_uid.pkl', 'rb') as f:\n",
    "        test_sam = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = {}\n",
    "for i in valid_sam:\n",
    "    poss, negs, his, uid, tsp = i\n",
    "    if uid not in user_count.keys():\n",
    "        user_count[uid] = 0\n",
    "    else:\n",
    "        user_count[uid] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.5016e+04, 4.1980e+03, 6.4200e+02, 6.5000e+01, 5.3000e+01,\n",
       "        2.1000e+01, 3.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
       " array([ 0. ,  1.7,  3.4,  5.1,  6.8,  8.5, 10.2, 11.9, 13.6, 15.3, 17. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(list(user_count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'nid2index.pkl', 'rb') as f:\n",
    "    nid2index = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'vocab_dict.pkl', 'rb') as f:\n",
    "    vocab_dict = pickle.load(f)\n",
    "\n",
    "embedding_matrix = np.load(data_path/'embedding.npy')\n",
    "news_index = np.load(data_path /'news_index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_data_path = Path(\"/home/v-mezhang/blob-plm/data/large/utils/\")\n",
    "# embedding_matrix = np.load(large_data_path/'embedding.npy')\n",
    "# embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(data_path/'test_nid2index.pkl'):\n",
    "    with open(data_path/'test_nid2index.pkl', 'rb') as f:\n",
    "        test_nid2index = pickle.load(f)\n",
    "\n",
    "    test_news_index = np.load(data_path /'test_news_index.npy')\n",
    "else: # TODO: for now use valid to do test (cb)\n",
    "    test_nid2index = nid2index\n",
    "    test_news_index = news_index\n",
    "    test_sam = valid_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ctr(samples, news_click_count, news_impr_count, interval_time,):\n",
    "    for l in tqdm(samples):\n",
    "        pos, neg, his, uid, tsp = l\n",
    "        tsp = datetime.strptime(tsp,date_format_str)\n",
    "        tidx = int((tsp - start_time).total_seconds()/interval_time) \n",
    "        if type(pos) is list:\n",
    "            for i in pos:\n",
    "                nidx = nid2index[i]\n",
    "                news_click_count[nidx, tidx] += 1\n",
    "                news_impr_count[nidx, tidx] += 1\n",
    "        else:\n",
    "            nidx = nid2index[pos]\n",
    "            news_click_count[nidx, tidx] += 1\n",
    "            news_impr_count[nidx, tidx] += 1\n",
    "\n",
    "        for i in neg:\n",
    "            nidx = nid2index[i]\n",
    "            news_impr_count[nidx, tidx] += 1\n",
    "    return news_click_count, news_impr_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65239\n",
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "interval_time = 3600\n",
    "start_time =  datetime.strptime(sorted_train_sam[0][-1],date_format_str)\n",
    "# print(start_time)\n",
    "end_time = datetime.strptime(valid_sam[-1][-1],date_format_str)\n",
    "nt = int((end_time - start_time).total_seconds()/interval_time) + 1 \n",
    "print(len(nid2index))\n",
    "print(nt)\n",
    "news_click_count = np.zeros((len(nid2index), nt), dtype=float)\n",
    "news_impr_count = np.ones((len(nid2index), nt), dtype=float) * 100 # assume 100 times init\n",
    "\n",
    "news_click_count, news_impr_count = cal_ctr(train_sam, news_click_count, news_impr_count, interval_time)\n",
    "news_click_count, news_impr_count = cal_ctr(valid_sam, news_click_count, news_impr_count, interval_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_ctr = np.zeros_like(news_click_count)\n",
    "# for i in tqdm(range(news_click_count.shape[0])):\n",
    "#     for j in range(news_click_count.shape[1]):\n",
    "#         if news_impr_count[i,j] == 0:\n",
    "#             assert news_click_count[i,j] == 0\n",
    "#             news_ctr[i,j] = 0\n",
    "#         else:\n",
    "#             news_ctr[i,j] = news_click_count[i,j]/news_impr_count[i,j]\n",
    "news_ctr = news_click_count/news_impr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# news_ctr = news_click_count/news_impr_count\n",
    "# plt.imshow(news_ctr[:,166])\n",
    "# plt.colorbar()\n",
    "tidx = 111\n",
    "nonzero = news_ctr[:,tidx][news_ctr[:, tidx] > 0]\n",
    "len(nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([27., 20., 31., 25., 16.,  7., 32.,  2.,  4.,  4.]),\n",
       " array([ 95. , 156.3, 217.6, 278.9, 340.2, 401.5, 462.8, 524.1, 585.4,\n",
       "        646.7, 708. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nonzero_count = []\n",
    "for i in range(news_click_count.shape[1]):\n",
    "    nonzero = news_ctr[:,i][news_ctr[:, i] > 0]\n",
    "    nonzero_count.append(len(nonzero))\n",
    "plt.hist(nonzero_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsample(nnn, ratio):\n",
    "    if ratio > len(nnn):\n",
    "        return nnn + [\"<unk>\"] * (ratio - len(nnn))\n",
    "    else:\n",
    "        return random.sample(nnn, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, samples, nid2index, news_index):\n",
    "        self.news_index = news_index\n",
    "        self.nid2index = nid2index\n",
    "        self.samples = samples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # pos, neg, his, neg_his\n",
    "        pos, neg, his, uid, tsp = self.samples[idx]\n",
    "        neg = newsample(neg, npratio)\n",
    "        \n",
    "        candidate_news = [pos] + neg\n",
    "        # print('pos: ', pos)\n",
    "        # for n in candidate_news:\n",
    "        #     print(n)\n",
    "        #     print(self.nid2index[n])\n",
    "        if type(candidate_news[0]) is str:\n",
    "            assert candidate_news[0].startswith('N') # nid\n",
    "            candidate_news = self.news_index[[self.nid2index[n] for n in candidate_news]]\n",
    "        else: # nindex\n",
    "            candidate_news = self.news_index[[n for n in candidate_news]]\n",
    "        his = [self.nid2index[n] for n in his] + [0] * (max_his_len - len(his))\n",
    "        his = self.news_index[his]\n",
    "        \n",
    "        label = np.array(0)\n",
    "        return candidate_news, his, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_index):\n",
    "        self.news_index = news_index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.news_index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.news_index[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = NewsDataset(news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 samples,\n",
    "                 news_vecs,\n",
    "                 nid2index):\n",
    "        self.samples = samples\n",
    "        self.news_vecs = news_vecs\n",
    "        self.nid2index = nid2index\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        poss, negs, his, uid, tsp = self.samples[idx]\n",
    "        his = [self.nid2index[n] for n in his] + [0] * (max_his_len - len(his))\n",
    "        his = self.news_vecs[his]\n",
    "        return his, tsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True)  + 1e-8)\n",
    "        \n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model # 300\n",
    "        self.n_heads = n_heads # 20\n",
    "        self.d_k = d_k # 20\n",
    "        self.d_v = d_v # 20\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads) # 300, 400\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "                \n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1).expand(batch_size, max_len, max_len) \n",
    "            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "        \n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s, attn_mask) \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) \n",
    "        return context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    ''' AttentionPooling used to weighted aggregate news vectors\n",
    "    Arg: \n",
    "        d_h: the last dimension of input\n",
    "    '''\n",
    "    def __init__(self, d_h, hidden_size=200):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(d_h, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, candidate_vector_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, candidate_vector_dim\n",
    "        \"\"\"\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "\n",
    "        alpha = torch.exp(alpha)\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha)\n",
    "        x = torch.reshape(x, (bz, -1))  # (bz, 400)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 word_embedding_dim=300, \n",
    "                 num_attention_heads=20,\n",
    "                 query_vector_dim = 200,\n",
    "                 dropout_rate=0.2,\n",
    "                 enable_gpu=True):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.dropout_rate = 0.2\n",
    "        pretrained_news_word_embedding = torch.from_numpy(embedding_matrix).float()\n",
    "        \n",
    "        self.word_embedding = nn.Embedding.from_pretrained(\n",
    "            pretrained_news_word_embedding, freeze=False)\n",
    "        \n",
    "        self.multihead_attention = MultiHeadAttention(word_embedding_dim,\n",
    "                                              num_attention_heads, 20, 20)\n",
    "        self.additive_attention = AdditiveAttention(num_attention_heads*20,\n",
    "                                                    query_vector_dim)\n",
    "    def forward(self, text):\n",
    "        # REVIEW: remove training=self.training to enable dropout during testing \n",
    "        text_vector = F.dropout(self.word_embedding(text.long()),\n",
    "                                p=self.dropout_rate,\n",
    "                                # training=self.training\n",
    "                                )\n",
    "        multihead_text_vector = self.multihead_attention(\n",
    "            text_vector, text_vector, text_vector)\n",
    "        multihead_text_vector = F.dropout(multihead_text_vector,\n",
    "                                          p=self.dropout_rate,\n",
    "                                        #   training=self.training\n",
    "                                          )\n",
    "        # batch_size, word_embedding_dim\n",
    "        text_vector = self.additive_attention(multihead_text_vector)\n",
    "        return text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 news_embedding_dim=400,\n",
    "                 num_attention_heads=20,\n",
    "                 query_vector_dim=200\n",
    "                ):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        self.multihead_attention = MultiHeadAttention(news_embedding_dim,\n",
    "                                              num_attention_heads, 20, 20)\n",
    "        self.additive_attention = AdditiveAttention(num_attention_heads*20,\n",
    "                                                    query_vector_dim)\n",
    "        \n",
    "        self.neg_multihead_attention = MultiHeadAttention(news_embedding_dim,\n",
    "                                                         num_attention_heads, 20, 20)\n",
    "        \n",
    "    def forward(self, clicked_news_vecs):\n",
    "        multi_clicked_vectors = self.multihead_attention(\n",
    "            clicked_news_vecs, clicked_news_vecs, clicked_news_vecs\n",
    "        )\n",
    "        pos_user_vector = self.additive_attention(multi_clicked_vectors)\n",
    "        \n",
    "        user_vector = pos_user_vector\n",
    "        return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRMS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NRMS, self).__init__()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.user_encoder = UserEncoder()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, candidate_news, clicked_news, targets, compute_loss=True):\n",
    "        batch_size, npratio, word_num = candidate_news.shape\n",
    "        candidate_news = candidate_news.view(-1, word_num)\n",
    "        candidate_vector = self.text_encoder(candidate_news).view(batch_size, npratio, -1)\n",
    "        \n",
    "        batch_size, clicked_news_num, word_num = clicked_news.shape\n",
    "        clicked_news = clicked_news.view(-1, word_num)\n",
    "        clicked_news_vecs = self.text_encoder(clicked_news).view(batch_size, clicked_news_num, -1)\n",
    "        \n",
    "        user_vector = self.user_encoder(clicked_news_vecs)\n",
    "        \n",
    "        score = torch.bmm(candidate_vector, user_vector.unsqueeze(-1)).squeeze(dim=-1)\n",
    "        \n",
    "        if compute_loss:\n",
    "            loss = self.criterion(score, targets)\n",
    "            return loss, score\n",
    "        else:\n",
    "            return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amn(y_true, y_score):\n",
    "    auc = roc_auc_score(y_true,y_score)\n",
    "    mrr = mrr_score(y_true,y_score)\n",
    "    ndcg5 = ndcg_score(y_true,y_score,5)\n",
    "    ndcg10 = ndcg_score(y_true,y_score,10)\n",
    "    return auc, mrr, ndcg5, ndcg10\n",
    "\n",
    "def evaluation_split(news_vecs, user_vecs, samples, nid2index):\n",
    "    all_rslt = []\n",
    "    for i in tqdm(range(len(samples))):\n",
    "        poss, negs, _, _, _ = samples[i]\n",
    "        user_vec = user_vecs[i]\n",
    "        y_true = [1] * len(poss) + [0] * len(negs)\n",
    "        news_ids = [nid2index[i] for i in poss + negs]\n",
    "        news_vec = news_vecs[news_ids]\n",
    "        y_score = np.multiply(news_vec, user_vec)\n",
    "        y_score = np.sum(y_score, axis=1)\n",
    "        try:\n",
    "            all_rslt.append(compute_amn(y_true, y_score))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return np.array(all_rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TrainDataset(train_sam, nid2index, news_index)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    for time in range(1):\n",
    "        model = NRMS().to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            model = nn.DataParallel(model, device_ids=[0,1,2]) \n",
    "        else:\n",
    "            print('single GPU found.')\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        best_auc = 0\n",
    "        for ep in range(epoch):\n",
    "            loss = 0\n",
    "            accuary = 0.0\n",
    "            model.train()\n",
    "            train_loader = tqdm(train_dl)\n",
    "            for cnt, batch_sample in enumerate(train_loader):\n",
    "                candidate_news_index, his_index, label = batch_sample\n",
    "                sample_num = candidate_news_index.shape[0]\n",
    "                candidate_news_index = candidate_news_index.to(device)\n",
    "                his_index = his_index.to(device)\n",
    "                label = label.to(device)\n",
    "                bz_loss, y_hat = model(candidate_news_index, his_index, label)\n",
    "\n",
    "                loss += bz_loss.detach().cpu().numpy()\n",
    "                optimizer.zero_grad()\n",
    "                bz_loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                if cnt % 10 == 0:\n",
    "                    train_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                    train_loader.refresh() \n",
    "\n",
    "\n",
    "            model.eval()\n",
    "            news_dl = DataLoader(news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(valid_sam, news_vecs, nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            for his, tsp in tqdm(user_dl):\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            val_scores = evaluation_split(news_vecs, user_vecs, valid_sam, nid2index)\n",
    "            val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*val_scores))]\n",
    "            print(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\")\n",
    "\n",
    "            with open(model_path/f'{name}.txt', 'a') as f:\n",
    "                f.write(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "                    \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                torch.save(model.state_dict(), model_path/f'{name}.pkl')\n",
    "                with open(model_path/f'{name}.txt', 'a') as f:\n",
    "                    f.write(f\"[{ep}] epoch save model\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eva_metric(y_scores, y_trues):\n",
    "    all_rslt_mean = []\n",
    "    all_rslt_ucb1 = []\n",
    "    all_rslt_ucb05 = []\n",
    "    all_rslt_ucb15 = []\n",
    "\n",
    "    for key, value in y_scores.items():\n",
    "        mean = np.asarray(value).mean(axis = 0)\n",
    "        std = np.asarray(value).std(axis = 0)\n",
    "        # print(utc.metrics.get_all_metrics(mean, std, np.array(y_trues[key])))\n",
    "        try:\n",
    "            all_rslt_mean.append(compute_amn(y_trues[key], mean))\n",
    "            all_rslt_ucb1.append(compute_amn(y_trues[key], mean + std ))\n",
    "            all_rslt_ucb05.append(compute_amn(y_trues[key], mean + 0.5 * std ))\n",
    "            all_rslt_ucb15.append(compute_amn(y_trues[key], mean + 1.5 * std ))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_mean)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 0 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "\n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb05)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 0.5 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "        \n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb1)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 1 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "   \n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb15)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 1.5 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = NRMS().to(device)\n",
    "model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "model.eval()\n",
    "\n",
    "y_scores = []\n",
    "y_trues = []\n",
    "\n",
    "with torch.no_grad():    \n",
    "    test_news_dataset = NewsDataset(news_index)\n",
    "    news_dl = DataLoader(news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "    news_vecs = []\n",
    "    for news in tqdm(news_dl):\n",
    "        news = news.to(device)\n",
    "        news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "        news_vecs.append(news_vec)\n",
    "    news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "    user_dataset = UserDataset(train_sam, news_vecs, nid2index)\n",
    "    user_vecs = []\n",
    "    user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "    for his_tsp in tqdm(user_dl):\n",
    "        his, _ = his_tsp\n",
    "        his = his.to(device)\n",
    "        user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "        user_vecs.append(user_vec)\n",
    "    user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "    for i in tqdm(range(len(train_sam))):\n",
    "        poss, negs, _, _, _ = train_sam[i]\n",
    "        user_vec = user_vecs[i]\n",
    "        y_true = [1] + [0] * len(negs)\n",
    "        news_ids = [nid2index[i] for i in [poss] + negs]\n",
    "        news_vec = news_vecs[news_ids]\n",
    "        y_score = np.multiply(news_vec, user_vec)\n",
    "        y_score = np.sum(y_score, axis=1)\n",
    "\n",
    "        y_scores.append(y_score)\n",
    "        y_trues.append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "y_scores = flatten(y_scores)\n",
    "y_trues = flatten(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.000000e+00, 1.540000e+02, 3.826000e+03, 1.277510e+05,\n",
       "        2.300891e+06, 7.020500e+06, 1.723576e+06, 7.582700e+04,\n",
       "        1.923000e+03, 6.300000e+01]),\n",
       " array([-9.480633 , -7.6813517, -5.8820705, -4.082789 , -2.2835078,\n",
       "        -0.4842267,  1.3150545,  3.1143358,  4.913617 ,  6.7128983,\n",
       "         8.512179 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5b100aa4a8>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x = y_scores, y = y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = NRMS().to(device)\n",
    "model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "model.eval()\n",
    "\n",
    "y_scores = defaultdict(list)\n",
    "y_trues = {}\n",
    "\n",
    "with torch.no_grad():    \n",
    "    test_news_dataset = NewsDataset(test_news_index)\n",
    "    news_dl = DataLoader(test_news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "    news_vecs = []\n",
    "    for news in tqdm(news_dl):\n",
    "        news = news.to(device)\n",
    "        news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "        news_vecs.append(news_vec)\n",
    "    news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "    user_dataset = UserDataset(test_sam, news_vecs, test_nid2index)\n",
    "    user_vecs = []\n",
    "    user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "    for his_tsp in tqdm(user_dl):\n",
    "        his, _ = his_tsp\n",
    "        his = his.to(device)\n",
    "        user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "        user_vecs.append(user_vec)\n",
    "    user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "    for i in tqdm(range(len(valid_sam))):\n",
    "        poss, negs, _, _, _ = valid_sam[i]\n",
    "        user_vec = user_vecs[i]\n",
    "        y_true = [1] * len(poss) + [0] * len(negs)\n",
    "        news_ids = [nid2index[i] for i in poss + negs]\n",
    "        news_vec = news_vecs[news_ids]\n",
    "        y_score = np.multiply(news_vec, user_vec)\n",
    "        y_score = np.sum(y_score, axis=1)\n",
    "\n",
    "        y_scores[i].append(y_score)\n",
    "        y_trues[i] = y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offline \n",
    "\n",
    "if offline_flag:\n",
    "    model = NRMS().to(device)\n",
    "    model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "    model.eval()\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('dropout'):\n",
    "            print(m)\n",
    "            m.train()\n",
    "\n",
    "    y_scores = defaultdict(list)\n",
    "    y_trues = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in tqdm(range(eva_times)):\n",
    "            test_news_dataset = NewsDataset(test_news_index)\n",
    "            news_dl = DataLoader(test_news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(test_sam, news_vecs, test_nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            for his_tsp in tqdm(user_dl):\n",
    "                his, _ = his_tsp\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            for i in tqdm(range(len(valid_sam))):\n",
    "                poss, negs, _, _, _ = valid_sam[i]\n",
    "                user_vec = user_vecs[i]\n",
    "                y_true = [1] * len(poss) + [0] * len(negs)\n",
    "                news_ids = [nid2index[i] for i in poss + negs]\n",
    "                news_vec = news_vecs[news_ids]\n",
    "                y_score = np.multiply(news_vec, user_vec)\n",
    "                y_score = np.sum(y_score, axis=1)\n",
    "                \n",
    "                y_scores[i].append(y_score)\n",
    "                y_trues[i] = y_true\n",
    "\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"offline eva with eva : {eva_times} times\\n\")\n",
    "    print_eva_metric(y_scores, y_trues)\n",
    "\n",
    "    # test_auc, test_mrr, test_ndcg, test_ndcg10 = [np.mean(i) for i in list(zip(*test_scores))]\n",
    "    # print(f\"[{i}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\")\n",
    "\n",
    "# with open(model_path/ f'{name}.txt', 'a') as f:\n",
    "#         f.write(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_trainable_samples(samples):\n",
    "    tr_samples = []\n",
    "    for l in samples:\n",
    "        pos_imp, neg_imp, his, uid, tsp = l    \n",
    "        for pos in list(pos_imp):\n",
    "            tr_samples.append([pos, neg_imp, his, uid, tsp])\n",
    "    return tr_samples\n",
    "\n",
    "\n",
    "\n",
    "def finetune(model, ft_sam, nid2index, news_index, batch_size):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    ft_sam = construct_trainable_samples(ft_sam)\n",
    "    ft_ds = TrainDataset(ft_sam, nid2index, news_index)\n",
    "    ft_dl = DataLoader(ft_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    for ep in range(epoch):\n",
    "        loss = 0\n",
    "        accuary = 0.0\n",
    "        model.train()\n",
    "        ft_loader = tqdm(ft_dl)\n",
    "        for cnt, batch_sample in enumerate(ft_loader):\n",
    "            candidate_news_index, his_index, label = batch_sample\n",
    "            sample_num = candidate_news_index.shape[0]\n",
    "            candidate_news_index = candidate_news_index.to(device)\n",
    "            his_index = his_index.to(device)\n",
    "            label = label.to(device)\n",
    "            bz_loss, y_hat = model(candidate_news_index, his_index, label)\n",
    "\n",
    "            loss += bz_loss.detach().cpu().numpy()\n",
    "            optimizer.zero_grad()\n",
    "            bz_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if cnt % 10 == 0:\n",
    "                ft_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                ft_loader.refresh() \n",
    "\n",
    "    return model \n",
    "\n",
    "def eva_batch(model, droupout_flag, batch_news_index, batch_sam, batch_nid2index, y_scores, y_trues, ucbs, batch_size, batch_id):\n",
    "    model.eval()\n",
    "    if droupout_flag:\n",
    "        for m in model.modules():\n",
    "            if m.__class__.__name__.startswith('dropout'):\n",
    "                print(m)\n",
    "                m.train()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(eva_times)):\n",
    "            batch_news_dataset = NewsDataset(batch_news_index)\n",
    "            news_dl = DataLoader(batch_news_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(batch_sam, news_vecs, batch_nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "\n",
    "            for his_tsp in tqdm(user_dl):\n",
    "                his, tsp = his_tsp\n",
    "                batch_time = datetime.strptime(str(tsp[-1]), date_format_str)\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "                # print(tsp)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            start_id = batch_size * batch_id\n",
    "\n",
    "            for i in tqdm(range(len(batch_sam))):\n",
    "                poss, negs, _, _,_ = batch_sam[i]\n",
    "                user_vec = user_vecs[i]\n",
    "                y_true = [1] * len(poss) + [0] * len(negs)\n",
    "                news_ids = [nid2index[i] for i in poss + negs]\n",
    "                news_vec = news_vecs[news_ids]\n",
    "                y_score = np.multiply(news_vec, user_vec)\n",
    "                y_score = np.sum(y_score, axis=1)\n",
    "                \n",
    "                y_scores[start_id+i].append(y_score)\n",
    "                y_trues[start_id+i] = y_true\n",
    "                \n",
    "    return y_scores, y_trues, batch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# online \n",
    "\n",
    "if online_flag:\n",
    "\n",
    "    print('online eva')\n",
    "\n",
    "    model = NRMS().to(device)\n",
    "    model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "\n",
    "    y_scores = defaultdict(list)\n",
    "    y_trues = {}\n",
    "\n",
    "    update_time = None\n",
    "    update_batch = 0\n",
    "    batch_size = 1024\n",
    "    dropout_flag = True\n",
    "\n",
    "    n_batch = math.ceil(float(len(test_sam))/batch_size)\n",
    "\n",
    "    for i in range(n_batch):\n",
    "        upper_range = min(1024 * (i+1), len(test_sam))\n",
    "        batch_sam = test_sam[1024 * i: upper_range]\n",
    "\n",
    "        y_scores, y_trues, batch_time = eva_batch(model, dropout_flag, test_news_index, batch_sam, test_nid2index, y_scores, y_trues, batch_size, i)\n",
    "        \n",
    "        num_sample = len(y_scores)\n",
    "        with open(model_path/f'{name}.txt', 'a') as f:\n",
    "            f.write(f\"online eva on batch : {i} with {num_sample} samples in current batch, up to index {upper_range}\\n\")\n",
    "        print_eva_metric(y_scores, y_trues)\n",
    "    \n",
    "        if update_time is None:\n",
    "            update_time = batch_time\n",
    "            print('init update time: ', update_time)\n",
    "        if (batch_time- update_time).total_seconds() > 3600:\n",
    "\n",
    "            ft_sam = test_sam[1024 * update_batch: upper_range]\n",
    "            if upper_range - 1024 * update_batch > 512:\n",
    "                print('finetune with: '  + str(1024 * update_batch) + ' ~ ' + str(upper_range))\n",
    "                model = finetune(model=model, ft_sam=ft_sam, nid2index=test_nid2index, news_index=test_news_index, batch_size=32)\n",
    "\n",
    "                update_time = batch_time\n",
    "                update_batch = i + 1\n",
    "                print('update before: ', update_time)\n",
    "            else: \n",
    "                print('no finetune due to insufficient samples: ', str(upper_range - 1024 * update_batch))\n",
    "\n",
    "    torch.save(model.state_dict(), model_path/f'{name}_finetune.pkl')\n",
    "# sys.stdout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandit Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CB_sim():\n",
    "    def __init__(\n",
    "        self, model_path, simulator_path, out_path, device,\n",
    "        news_index, nid2index,\n",
    "        finetune_batch_size = 32, eva_batch_size = 1024, dropout_flag = True\n",
    "    ):\n",
    "        self.model = NRMS().to(device)\n",
    "        self.model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "        \n",
    "        # TODO: change simulator to PLM\n",
    "        self.simulator = NRMS().to(device)\n",
    "        self.simulator.load_state_dict(torch.load(simulator_path/f'{name}.pkl'))\n",
    "\n",
    "        self.news_index = news_index\n",
    "        self.nid2index = nid2index\n",
    "\n",
    "        self.out_path = out_path\n",
    "        self.dropout_flag = dropout_flag\n",
    "        \n",
    "        self.finetune_batch_size = finetune_batch_size\n",
    "        self.eva_batch_size = eva_batch_size\n",
    "        self.date_format_str = '%m/%d/%Y %I:%M:%S %p'\n",
    "\n",
    "    \n",
    "    def enable_dropout(self):\n",
    "        for m in self.model.modules():\n",
    "            if m.__class__.__name__.startswith('dropout'):\n",
    "                print(m)\n",
    "                m.train() \n",
    "        \n",
    "    def get_news_vec(self, model, batch_news_index):\n",
    "        batch_news_dataset = NewsDataset(batch_news_index)\n",
    "        news_dl = DataLoader(batch_news_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        news_vecs = []\n",
    "        for news in tqdm(news_dl):\n",
    "            news = news.to(device)\n",
    "            news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "            news_vecs.append(news_vec)\n",
    "        news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "        return news_vecs\n",
    "\n",
    "    def get_user_vec(self, model, batch_sam, news_vecs, batch_nid2index):\n",
    "        user_dataset = UserDataset(batch_sam, news_vecs, batch_nid2index)\n",
    "        user_vecs = []\n",
    "        user_dl = DataLoader(user_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        for his_tsp in tqdm(user_dl):\n",
    "            his, tsp = his_tsp\n",
    "            his = his.to(device)\n",
    "            user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "            user_vecs.append(user_vec)\n",
    "            # print(tsp)\n",
    "        user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "        return user_vecs\n",
    "        \n",
    "    def get_cand_news(self, t, poss, negs, m = 10):\n",
    "        \"\"\"\n",
    "        Generate candidates news based on CTR.\n",
    "\n",
    "        t: string, impr time\n",
    "        poss: list, positive samples in impr\n",
    "        negs: list, neg samples in impr\n",
    "        m: int, number of candidate news to return\n",
    "\n",
    "        Return: array, candidate news id \n",
    "        \"\"\"\n",
    "        t = datetime.strptime(t,date_format_str)\n",
    "        tidx = int((t - start_time).total_seconds()/interval_time)\n",
    "\n",
    "        nonzero = news_ctr[:,tidx -1][news_ctr[:, tidx-1] > 0]\n",
    "        nonzero_idx = np.where(news_ctr[:, tidx-1] > 0)[0]\n",
    "        # print(nonzero_idx)\n",
    "\n",
    "        nonzero = nonzero/nonzero.sum()\n",
    "        assert (nonzero.sum() - 1) < 1e-3\n",
    "        # print(np.sort(nonzero)[-5:])\n",
    "\n",
    "        # sampling according to normalised ctr in last one hour\n",
    "        sample_nids = np.random.choice(nonzero_idx, size = m, replace = False, p = nonzero)\n",
    "        # REVIEW: check whether the sampled nids are reasonable\n",
    "        \n",
    "        # print(news_ctr[sample_nidx, tidx-1])\n",
    "        # plt.hist(nonzero)\n",
    "        # print(poss)\n",
    "        # print(negs)\n",
    "        poss_nids = np.array([self.nid2index[n] for n in poss])\n",
    "        negs_nids = np.array([self.nid2index[n] for n in negs])\n",
    "        # print('get cand news')\n",
    "        # print(sample_nids)\n",
    "        # print(poss_nids)\n",
    "        # print(negs_nids)\n",
    "\n",
    "        return np.concatenate([sample_nids, poss_nids, negs_nids])\n",
    "        \n",
    "#     t =  sorted_train_sam[1500][-1]\n",
    "#     gene_news_pool(t, 20)\n",
    "\n",
    "    def construct_trainable_samples(self, samples):\n",
    "        tr_samples = []\n",
    "        for l in samples:\n",
    "            pos_imp, neg_imp, his, uid, tsp = l    \n",
    "            for pos in list(pos_imp):\n",
    "                tr_samples.append([pos, neg_imp, his, uid, tsp])\n",
    "        return tr_samples\n",
    "\n",
    "    def finetune(self, ft_sam):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        ft_sam = self.construct_trainable_samples(ft_sam)\n",
    "        ft_ds = TrainDataset(ft_sam, self.nid2index, self.news_index)\n",
    "        ft_dl = DataLoader(ft_ds, batch_size=self.finetune_batch_size, shuffle=True, num_workers=0)\n",
    "        for ep in range(epoch):\n",
    "            loss = 0\n",
    "            accuary = 0.0\n",
    "            self.model.train()\n",
    "            ft_loader = tqdm(ft_dl)\n",
    "            for cnt, batch_sample in enumerate(ft_loader):\n",
    "                candidate_news_index, his_index, label = batch_sample\n",
    "                sample_num = candidate_news_index.shape[0]\n",
    "                candidate_news_index = candidate_news_index.to(device)\n",
    "                his_index = his_index.to(device)\n",
    "                label = label.to(device)\n",
    "                bz_loss, y_hat = self.model(candidate_news_index, his_index, label)\n",
    "\n",
    "                loss += bz_loss.detach().cpu().numpy()\n",
    "                optimizer.zero_grad()\n",
    "                bz_loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                if cnt % 10 == 0:\n",
    "                    ft_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                    ft_loader.refresh() \n",
    "\n",
    "    def get_ucb_score(self, exper_id, y_score, t):\n",
    "        ucb = []\n",
    "        beta_t = 1\n",
    "\n",
    "        mean = np.asarray(y_score).mean(axis = 0)\n",
    "        std = np.asarray(y_score).std(axis = 0)\n",
    "        ucb_score = mean + beta_t * std\n",
    "\n",
    "        rec_nids = np.argsort(ucb_score)[-k:]\n",
    "        return rec_nids\n",
    "\n",
    "    def epsilon_greedy(self, exper_id, y_score, k):\n",
    "        rec = []\n",
    "        y_score = y_score[0]\n",
    "        p = np.random.rand(k)\n",
    "        n_greedy = int(len(p[p > self.policy_para]))\n",
    "        greedy_nids = np.argsort(y_score)[-n_greedy:]\n",
    "        eps_nids = np.random.choice(np.array(list(set(range(len(y_score))) - set(greedy_nids))), size = k - n_greedy, replace=False)\n",
    "        rec_nids= np.concatenate([greedy_nids, eps_nids])\n",
    "        return rec_nids\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return np.array([1/(1 + math.exp(-i)) for i in x])\n",
    "                \n",
    "    def rec(self, batch_sam, batch_id, exper_id, k = 8):\n",
    "        \"\"\"\n",
    "        Simulate recommendations\n",
    "        \"\"\"\n",
    "        if self.policy == 'epsilon_greedy':\n",
    "            self.n_inference = 1\n",
    "        \n",
    "        self.model.eval()\n",
    "        if self.dropout_flag:\n",
    "            self.enable_dropout()\n",
    "\n",
    "        y_scores = defaultdict(list) # key: sam_id, value: list of n_inference scores \n",
    "        cand_nids_dict = {} # key: sam_id, value: array of candidate news ids\n",
    "        start_id = self.eva_batch_size * batch_id\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sim_news_vecs = self.get_news_vec(self.simulator, self.news_index)\n",
    "            sim_user_vecs = self.get_user_vec(self.simulator, batch_sam, sim_news_vecs, self.nid2index) \n",
    "\n",
    "            # generate scores with uncertainty (dropout during inference)\n",
    "            for _ in tqdm(range(self.n_inference)):\n",
    "                # TODO: speed up - only pass batch news index\n",
    "                news_vecs = self.get_news_vec(self.model, self.news_index)\n",
    "                user_vecs = self.get_user_vec(self.model, batch_sam, news_vecs, self.nid2index)\n",
    "                \n",
    "                for i in range(len(batch_sam)):\n",
    "                    t = start_id + i\n",
    "                    poss, negs, his, uid, tsq = batch_sam[i]     \n",
    "                    user_vec = user_vecs[i]\n",
    "                    \n",
    "                    if t not in cand_nids_dict.keys():\n",
    "                        # cand set (is a randomised set) keeps same for inference times\n",
    "                        cand_nids = self.get_cand_news(tsq, poss, negs)\n",
    "                        cand_nids_dict[t] = cand_nids\n",
    "                        # print(cand_nids)\n",
    "                        news_vec = news_vecs[cand_nids]\n",
    "                        sim_user_vec = sim_user_vecs[i]\n",
    "                        sim_news_vec = sim_news_vecs[cand_nids]\n",
    "                        sim_y_score = np.sum(np.multiply(sim_news_vec, sim_user_vec), axis=1)\n",
    "                        # assume the user would at most click half of the recommended news\n",
    "                        opt_nids = np.argsort(sim_y_score)[-int(k/2):] \n",
    "                        # print(opt_nids)\n",
    "                        # print(self.sigmoid(sim_y_score[opt_nids]))\n",
    "                        opt_nids = opt_nids[self.sigmoid(sim_y_score[opt_nids]) > 0.5]\n",
    "                        # print(opt_nids)\n",
    "                        self.opts[exper_id].append(opt_nids)   \n",
    "                    \n",
    "                    news_vec = news_vecs[cand_nids_dict[t]]\n",
    "                    y_score = np.sum(np.multiply(news_vec, user_vec), axis=1)\n",
    "                    y_scores[t].append(y_score)\n",
    "\n",
    "        # generate recommendations and calculate rewards\n",
    "        for i in range(len(batch_sam)):\n",
    "            t = start_id + i\n",
    "            _, _, his, uid, tsq = batch_sam[i]  \n",
    "\n",
    "            if self.policy == 'ucb':\n",
    "                rec_nids = self.get_ucb_score(exper_id, y_scores[t], t)\n",
    "            elif self.policy == 'epsilon_greedy':\n",
    "                rec_nids = self.epsilon_greedy(exper_id, y_scores[t], k)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            self.recs[exper_id].append(rec_nids) \n",
    "            \n",
    "            opt_nids = self.opts[exper_id][i]\n",
    " \n",
    "            assert len(set(rec_nids)) == k\n",
    "            # assert len(set(opt_nids)) == k\n",
    "\n",
    "            reward = len(set(rec_nids) & set(opt_nids)) # reward as the overlap between rec and opt set\n",
    "            # self.cumu_reward += reward\n",
    "            self.rewards[exper_id, t] = reward\n",
    "            self.opt_rewards[exper_id, t] = len(set(opt_nids))\n",
    "\n",
    "            rec_poss = [rec_nid for rec_nid in rec_nids if rec_nid in opt_nids]\n",
    "            # let all \n",
    "            rec_negs = list(set(cand_nids_dict[t]) - set(rec_poss))\n",
    "            \n",
    "            self.rec_sam.append([rec_poss, rec_negs, his, uid, tsq])\n",
    "        \n",
    "    def run_exper(self, test_sam, num_exper = 10, n_inference = 2, policy = 'ucb', policy_para = 0.1):\n",
    "        \n",
    "        num_sam = len(test_sam)\n",
    "        n_batch = math.ceil(float(num_sam)/self.eva_batch_size)\n",
    "        self.rec_sam = []\n",
    "        self.rewards = np.zeros((num_exper, num_sam))\n",
    "        self.opt_rewards = np.zeros((num_exper, num_sam))\n",
    "        self.recs = defaultdict(list)\n",
    "        self.opts = defaultdict(list)\n",
    "\n",
    "        self.n_inference = n_inference\n",
    "        self.policy = policy\n",
    "        self.policy_para = policy_para\n",
    "\n",
    "        update_time = None\n",
    "        update_batch = 0\n",
    "        \n",
    "\n",
    "        for j in range(num_exper):\n",
    "            # self.cumu_reward = 0\n",
    "            \n",
    "            for i in range(n_batch):\n",
    "                upper_range = min(self.eva_batch_size * (i+1), len(test_sam))\n",
    "                batch_sam = test_sam[self.eva_batch_size * i: upper_range]\n",
    "\n",
    "                self.rec(batch_sam, i, j)\n",
    "\n",
    "                if update_time is None:\n",
    "                    update_time = datetime.strptime(str(batch_sam[0][-1]), self.date_format_str)\n",
    "                    print('init time: ', update_time)\n",
    "\n",
    "                batch_time = datetime.strptime(str(batch_sam[-1][-1]), self.date_format_str)\n",
    "                if (batch_time- update_time).total_seconds() > 3600:\n",
    "                    lower_range = self.eva_batch_size * update_batch\n",
    "                    ft_sam = self.rec_sam[lower_range: upper_range]\n",
    "                    if upper_range - lower_range > 512:\n",
    "                        print('finetune with: '  + str(lower_range) + ' ~ ' + str(upper_range))\n",
    "                        self.finetune(ft_sam=ft_sam)\n",
    "\n",
    "                        update_time = batch_time\n",
    "                        update_batch = i + 1\n",
    "                        print('update at: ', update_time)\n",
    "                    else: \n",
    "                        print('no finetune due to insufficient samples: ', str(upper_range - lower_range))\n",
    "\n",
    "        self.save_results()\n",
    "\n",
    "    def save_results(self):\n",
    "        policy_name = self.policy + '_' + str(self.policy_para)\n",
    "        torch.save(self.model.state_dict(), os.path.join(model_path, (policy_name + f'_{name}_finetune.pkl')))\n",
    "        with open(os.path.join(self.out_path, (policy_name + \"_recs.pkl\")), \"wb\") as f:\n",
    "            pickle.dump(self.recs, f)\n",
    "        with open(os.path.join(self.out_path, (policy_name + \"_opts.pkl\")), \"wb\") as f:\n",
    "            pickle.dump(self.opts, f)\n",
    "        with open(os.path.join(self.out_path, (policy_name + \"_rewards.pkl\")), \"wb\") as f:\n",
    "            pickle.dump(self.rewards, f)\n",
    "        with open(os.path.join(self.out_path, (policy_name+ \"_opt_rewards.pkl\")), \"wb\") as f:\n",
    "            pickle.dump(self.opt_rewards, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cb_flag:\n",
    "    for para in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        print(para)\n",
    "        cb_sim = CB_sim(model_path=model_path, simulator_path=model_path, out_path=model_path, device=device, news_index=test_news_index, nid2index=test_nid2index)\n",
    "        cb_sim.run_exper(test_sam=test_sam, num_exper=2, n_inference = 2, policy='epsilon_greedy', policy_para=para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
