{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import copy\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = Path(\"/home/v-jingweiyi/data/FL/data/adressa\")\n",
    "data_path = Path(\"/data4/u6015325/data/adressa/utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "npratio = 4\n",
    "max_his_len = 50\n",
    "min_word_cnt = 3\n",
    "max_title_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epoch = 10\n",
    "lr=0.0001\n",
    "name = 'nrms-adressa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'train_contexts.pkl', 'rb') as f:\n",
    "    train_sam = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'valid_contexts.pkl', 'rb') as f:\n",
    "    valid_sam = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'test_contexts.pkl', 'rb') as f:\n",
    "    test_sam = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233275"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Preprocesss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'nid2index.pkl', 'rb') as f:\n",
    "    nid2index = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'vocab_dict.pkl', 'rb') as f:\n",
    "    vocab_dict = pickle.load(f)\n",
    "\n",
    "embedding_matrix = np.load(data_path/'embedding.npy')\n",
    "news_index = np.load(data_path /'news_index.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsample(nnn, ratio):\n",
    "    if ratio > len(nnn):\n",
    "        return nnn + [\"<unk>\"] * (ratio - len(nnn))\n",
    "    else:\n",
    "        return random.sample(nnn, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, samples, nid2index, news_index):\n",
    "        self.news_index = news_index\n",
    "        self.nid2index = nid2index\n",
    "        self.samples = samples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # pos, neg, his, neg_his\n",
    "        pos, neg, his, _, _ = self.samples[idx]\n",
    "        neg = newsample(neg, npratio)\n",
    "        candidate_news = [pos] + neg\n",
    "        candidate_news = self.news_index[[self.nid2index[n] for n in candidate_news]]\n",
    "        his = [self.nid2index[n] for n in his] + [0] * (max_his_len - len(his))\n",
    "        his = self.news_index[his]\n",
    "        \n",
    "        label = np.array(0)\n",
    "        return candidate_news, his, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_index):\n",
    "        self.news_index = news_index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.news_index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.news_index[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = NewsDataset(news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 samples,\n",
    "                 news_vecs,\n",
    "                 nid2index):\n",
    "        self.samples = samples\n",
    "        self.news_vecs = news_vecs\n",
    "        self.nid2index = nid2index\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        poss, negs, his, _, _ = self.samples[idx]\n",
    "        his = [self.nid2index[n] for n in his] + [0] * (max_his_len - len(his))\n",
    "        his = self.news_vecs[his]\n",
    "        return his"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True)  + 1e-8)\n",
    "        \n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model # 300\n",
    "        self.n_heads = n_heads # 20\n",
    "        self.d_k = d_k # 20\n",
    "        self.d_v = d_v # 20\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads) # 300, 400\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "                \n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1).expand(batch_size, max_len, max_len) \n",
    "            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "        \n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s, attn_mask) \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) \n",
    "        return context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    ''' AttentionPooling used to weighted aggregate news vectors\n",
    "    Arg: \n",
    "        d_h: the last dimension of input\n",
    "    '''\n",
    "    def __init__(self, d_h, hidden_size=200):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(d_h, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, candidate_vector_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, candidate_vector_dim\n",
    "        \"\"\"\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "\n",
    "        alpha = torch.exp(alpha)\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha)\n",
    "        x = torch.reshape(x, (bz, -1))  # (bz, 400)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 word_embedding_dim=300, \n",
    "                 num_attention_heads=20,\n",
    "                 query_vector_dim = 200,\n",
    "                 dropout_rate=0.2,\n",
    "                 enable_gpu=True):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.dropout_rate = 0.2\n",
    "        pretrained_news_word_embedding = torch.from_numpy(embedding_matrix).float()\n",
    "        \n",
    "        self.word_embedding = nn.Embedding.from_pretrained(\n",
    "            pretrained_news_word_embedding, freeze=True)\n",
    "        \n",
    "        self.multihead_attention = MultiHeadAttention(word_embedding_dim,\n",
    "                                              num_attention_heads, 20, 20)\n",
    "        self.additive_attention = AdditiveAttention(num_attention_heads*20,\n",
    "                                                    query_vector_dim)\n",
    "    def forward(self, text):\n",
    "        text_vector = F.dropout(self.word_embedding(text.long()),\n",
    "                                p=self.dropout_rate,\n",
    "                                training=self.training)\n",
    "        multihead_text_vector = self.multihead_attention(\n",
    "            text_vector, text_vector, text_vector)\n",
    "        multihead_text_vector = F.dropout(multihead_text_vector,\n",
    "                                          p=self.dropout_rate,\n",
    "                                          training=self.training)\n",
    "        # batch_size, word_embedding_dim\n",
    "        text_vector = self.additive_attention(multihead_text_vector)\n",
    "        return text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 news_embedding_dim=400,\n",
    "                 num_attention_heads=20,\n",
    "                 query_vector_dim=200\n",
    "                ):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        self.multihead_attention = MultiHeadAttention(news_embedding_dim,\n",
    "                                              num_attention_heads, 20, 20)\n",
    "        self.additive_attention = AdditiveAttention(num_attention_heads*20,\n",
    "                                                    query_vector_dim)\n",
    "        \n",
    "        self.neg_multihead_attention = MultiHeadAttention(news_embedding_dim,\n",
    "                                                         num_attention_heads, 20, 20)\n",
    "        self.dropout_rate = 0.2\n",
    "        \n",
    "    def forward(self, clicked_news_vecs):\n",
    "        multi_clicked_vectors =self.multihead_attention(\n",
    "            clicked_news_vecs, clicked_news_vecs, clicked_news_vecs\n",
    "        )\n",
    "        pos_user_vector = self.additive_attention(multi_clicked_vectors)\n",
    "        user_vector = pos_user_vector\n",
    "        return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.user_encoder = UserEncoder()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, candidate_news, clicked_news, targets, compute_loss=True):\n",
    "        batch_size, npratio, word_num = candidate_news.shape\n",
    "        candidate_news = candidate_news.view(-1, word_num)\n",
    "        candidate_vector = self.text_encoder(candidate_news).view(batch_size, npratio, -1)\n",
    "        \n",
    "        batch_size, clicked_news_num, word_num = clicked_news.shape\n",
    "        clicked_news = clicked_news.view(-1, word_num)\n",
    "        clicked_news_vecs = self.text_encoder(clicked_news).view(batch_size, clicked_news_num, -1)\n",
    "        \n",
    "        user_vector = self.user_encoder(clicked_news_vecs)\n",
    "        \n",
    "        score = torch.bmm(candidate_vector, user_vector.unsqueeze(-1)).squeeze(dim=-1)\n",
    "        \n",
    "        if compute_loss:\n",
    "            loss = self.criterion(score, targets)\n",
    "            return loss, score\n",
    "        else:\n",
    "            return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amn(y_true, y_score):\n",
    "    auc = roc_auc_score(y_true,y_score)\n",
    "    mrr = mrr_score(y_true,y_score)\n",
    "    ndcg5 = ndcg_score(y_true,y_score,5)\n",
    "    ndcg10 = ndcg_score(y_true,y_score,10)\n",
    "    return auc, mrr, ndcg5, ndcg10\n",
    "\n",
    "def evaluation_split(news_vecs, user_vecs, samples, nid2index):\n",
    "    all_rslt = []\n",
    "    for i in tqdm(range(len(samples))):\n",
    "        poss, negs, _, _, _ = samples[i]\n",
    "        user_vec = user_vecs[i]\n",
    "        y_true = [1] * len(poss) + [0] * len(negs)\n",
    "        news_ids = [nid2index[i] for i in poss + negs]\n",
    "        news_vec = news_vecs[news_ids]\n",
    "        y_score = np.multiply(news_vec, user_vec)\n",
    "        y_score = np.sum(y_score, axis=1)\n",
    "        try:\n",
    "            all_rslt.append(compute_amn(y_true, y_score))\n",
    "        except Exception as e:\n",
    "#             print(e)\n",
    "            print(y_score)\n",
    "    return np.array(all_rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TrainDataset(train_sam, nid2index, news_index)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "for time in range(5):\n",
    "    model = Model().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_auc = 0\n",
    "    for ep in range(1):\n",
    "        loss = 0\n",
    "        accuary = 0.0\n",
    "        model.train()\n",
    "        train_loader = tqdm(train_dl)\n",
    "        for cnt, batch_sample in enumerate(train_loader):\n",
    "            candidate_news_index, his_index, label = batch_sample\n",
    "            sample_num = candidate_news_index.shape[0]\n",
    "            candidate_news_index = candidate_news_index.to(device)\n",
    "            his_index = his_index.to(device)\n",
    "            label = label.to(device)\n",
    "            bz_loss, y_hat = model(candidate_news_index, his_index, label)\n",
    "           \n",
    "            loss += bz_loss.detach().cpu().numpy()\n",
    "            optimizer.zero_grad()\n",
    "            with autograd.detect_anomaly():\n",
    "                bz_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if cnt % 10 == 0:\n",
    "                train_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                train_loader.refresh() \n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        news_dl = DataLoader(news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "        news_vecs = []\n",
    "        for news in tqdm(news_dl):\n",
    "            news = news.to(device)\n",
    "            news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "            news_vecs.append(news_vec)\n",
    "        news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "        user_dataset = UserDataset(valid_sam, news_vecs, nid2index)\n",
    "        user_vecs = []\n",
    "        user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "        for his in tqdm(user_dl):\n",
    "            his = his.to(device)\n",
    "            user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "            user_vecs.append(user_vec)\n",
    "        user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "        val_scores = evaluation_split(news_vecs, user_vecs, valid_sam, nid2index)\n",
    "        val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*val_scores))]\n",
    "        print(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\")\n",
    "\n",
    "        with open(f'./rslt/{name}.txt', 'a') as f:\n",
    "              f.write(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "                \n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save(model.state_dict(), f'./model/{name}.pkl')\n",
    "            with open(f'./rslt/{name}.txt', 'a') as f:\n",
    "                f.write(f\"[{ep}] epoch save model\\n\")\n",
    "            \n",
    "    model.load_state_dict(torch.load(f'./model/{name}.pkl'))\n",
    "    test_news_dataset = NewsDataset(news_index)\n",
    "    news_dl = DataLoader(test_news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "    news_vecs = []\n",
    "    for news in tqdm(news_dl):\n",
    "        news = news.to(device)\n",
    "        news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "        news_vecs.append(news_vec)\n",
    "    news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "    user_dataset = UserDataset(test_sam, news_vecs, nid2index)\n",
    "    user_vecs = []\n",
    "    user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "    for his in tqdm(user_dl):\n",
    "        his = his.to(device)\n",
    "        user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "        user_vecs.append(user_vec)\n",
    "    user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "    test_scores = evaluation_split(news_vecs, user_vecs, test_sam, nid2index)\n",
    "    test_auc, test_mrr, test_ndcg, test_ndcg10 = [np.mean(i) for i in list(zip(*test_scores))]\n",
    "    print(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\")\n",
    "\n",
    "    with open(f'./rslt/{name}.txt', 'a') as f:\n",
    "          f.write(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 74.09it/s]\n",
      "100%|██████████| 178/178 [00:25<00:00,  6.96it/s]\n",
      "100%|██████████| 181847/181847 [03:59<00:00, 758.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<module 'time' (built-in)>] time test auc: 0.7174, mrr: 0.4254, ndcg5: 0.4386, ndcg10: 0.4831\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "model.load_state_dict(torch.load(f'./pretrained_models/{name}.pkl'))\n",
    "test_news_dataset = NewsDataset(news_index)\n",
    "news_dl = DataLoader(test_news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "news_vecs = []\n",
    "for news in tqdm(news_dl):\n",
    "    news = news.to(device)\n",
    "    news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "    news_vecs.append(news_vec)\n",
    "news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "user_dataset = UserDataset(test_sam, news_vecs, nid2index)\n",
    "user_vecs = []\n",
    "user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "for his in tqdm(user_dl):\n",
    "    his = his.to(device)\n",
    "    user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "    user_vecs.append(user_vec)\n",
    "user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "test_scores = evaluation_split(news_vecs, user_vecs, test_sam, nid2index)\n",
    "test_auc, test_mrr, test_ndcg, test_ndcg10 = [np.mean(i) for i in list(zip(*test_scores))]\n",
    "print(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\")\n",
    "\n",
    "with open(f'./rslt/{name}.txt', 'a') as f:\n",
    "      f.write(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "y_trues = []\n",
    "y_scores = []\n",
    "for i in tqdm(range(len(test_sam))):\n",
    "    poss, negs, _, _, _ = test_sam[i]\n",
    "    user_vec = user_vecs[i]\n",
    "    y_true = [1] * len(poss) + [0] * len(negs)\n",
    "    news_ids = [nid2index[i] for i in poss + negs]\n",
    "    news_vec = news_vecs[news_ids]\n",
    "    y_score = np.multiply(news_vec, user_vec)\n",
    "    y_score = np.sum(y_score, axis=1)\n",
    "        \n",
    "    y_trues.append(y_true)\n",
    "    y_scores.append(y_score)\n",
    "    \n",
    "y_trues = np.hstack(y_trues)\n",
    "y_scores = np.hstack(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3636940.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,  181847.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x)) \n",
    "plt.hist(sigmoid(y_scores))\n",
    "# plt.hist(y_scores)\n",
    "plt.hist(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Threshold=0.999974, fscore=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-e5945f1bb43c>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fscore = (2 * precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_trues, sigmoid(y_scores))\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "ix = np.argmax(fscore)\n",
    "print(' Best Threshold=%f, fscore=%.3f' % (thresholds[ix], fscore[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for time in range(9, 10):\n",
    "    model = Model().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_auc = 0\n",
    "    for ep in range(1):\n",
    "        loss = 0\n",
    "        accuary = 0.0\n",
    "        model.train()\n",
    "        train_loader = tqdm(train_dl)\n",
    "        for cnt, batch_sample in enumerate(train_loader):\n",
    "            candidate_news_index, his_index, label = batch_sample\n",
    "            sample_num = candidate_news_index.shape[0]\n",
    "            candidate_news_index = candidate_news_index.to(device)\n",
    "            his_index = his_index.to(device)\n",
    "            label = label.to(device)\n",
    "            bz_loss, y_hat = model(candidate_news_index, his_index, label)\n",
    "\n",
    "            loss += bz_loss.detach().cpu().numpy()\n",
    "            optimizer.zero_grad()\n",
    "            bz_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if cnt % 10 == 0:\n",
    "                train_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                train_loader.refresh() \n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        news_dl = DataLoader(news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "        news_vecs = []\n",
    "        for news in tqdm(news_dl):\n",
    "            news = news.to(device)\n",
    "            news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "            news_vecs.append(news_vec)\n",
    "        news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "        user_dataset = UserDataset(valid_sam, news_vecs, nid2index)\n",
    "        user_vecs = []\n",
    "        user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "        for his in tqdm(user_dl):\n",
    "            his = his.to(device)\n",
    "            user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "            user_vecs.append(user_vec)\n",
    "        user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "        val_scores = evaluation_split(news_vecs, user_vecs, valid_sam, nid2index)\n",
    "        val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*val_scores))]\n",
    "        print(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\")\n",
    "\n",
    "        with open(f'./rslt/{name}.txt', 'a') as f:\n",
    "              f.write(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "                \n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save(model.state_dict(), f'./model/{name}.pkl')\n",
    "            with open(f'./rslt/{name}.txt', 'a') as f:\n",
    "                f.write(f\"[{ep}] epoch save model\\n\")\n",
    "            \n",
    "    model.load_state_dict(torch.load(f'./model/{name}.pkl'))\n",
    "    test_news_dataset = NewsDataset(news_index)\n",
    "    news_dl = DataLoader(test_news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "    news_vecs = []\n",
    "    for news in tqdm(news_dl):\n",
    "        news = news.to(device)\n",
    "        news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "        news_vecs.append(news_vec)\n",
    "    news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "    user_dataset = UserDataset(test_sam, news_vecs, nid2index)\n",
    "    user_vecs = []\n",
    "    user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "    for his in tqdm(user_dl):\n",
    "        his = his.to(device)\n",
    "        user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "        user_vecs.append(user_vec)\n",
    "    user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "    test_scores = evaluation_split(news_vecs, user_vecs, test_sam, nid2index)\n",
    "    test_auc, test_mrr, test_ndcg, test_ndcg10 = [np.mean(i) for i in list(zip(*test_scores))]\n",
    "    print(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\")\n",
    "\n",
    "    with open(f'./rslt/{name}.txt', 'a') as f:\n",
    "          f.write(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e76a3758512e368b8e72161c8d9cfa8820f3db07cc330fdd71973458c082248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
