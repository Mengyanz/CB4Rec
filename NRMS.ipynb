{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import copy\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "from datetime import datetime \n",
    "import math\n",
    "import uncertainty_toolbox as utc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'demo/'\n",
    "\n",
    "data_path = Path(\"/home/v-mezhang/blob/data/\" + str(dataset) + \"utils/\")\n",
    "model_path = Path(\"/home/v-mezhang/blob/model/\" + str(dataset))\n",
    "\n",
    "date_format_str = '%m/%d/%Y %I:%M:%S %p'\n",
    "\n",
    "# sys.stdout = open(model_path / 'output.txt', \"w\")\n",
    "# print(model_path)\n",
    "# sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "npratio = 4\n",
    "max_his_len = 50\n",
    "min_word_cnt = 3\n",
    "max_title_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch = 1\n",
    "lr=0.0001\n",
    "name = 'nrms_' + dataset[:-1]\n",
    "retrain = False\n",
    "online_flag = False\n",
    "offline_flag = False\n",
    "cb_flag = True\n",
    "eva_times = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'train_sam_uid.pkl', 'rb') as f:\n",
    "    train_sam = pickle.load(f)\n",
    "\n",
    "with open(data_path/'sorted_train_sam_uid.pkl', 'rb') as f:\n",
    "    sorted_train_sam = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'sorted_valid_sam_uid.pkl', 'rb') as f:\n",
    "    valid_sam = pickle.load(f)\n",
    "\n",
    "if os.path.exists(data_path/'test_sam_uid.pkl'):    \n",
    "    with open(data_path/'test_sam_uid.pkl', 'rb') as f:\n",
    "        test_sam = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'nid2index.pkl', 'rb') as f:\n",
    "    nid2index = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'vocab_dict.pkl', 'rb') as f:\n",
    "    vocab_dict = pickle.load(f)\n",
    "\n",
    "embedding_matrix = np.load(data_path/'embedding.npy')\n",
    "news_index = np.load(data_path /'news_index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(data_path/'test_nid2index.pkl'):\n",
    "    with open(data_path/'test_nid2index.pkl', 'rb') as f:\n",
    "        test_nid2index = pickle.load(f)\n",
    "\n",
    "    test_news_index = np.load(data_path /'test_news_index.npy')\n",
    "else: # TODO: for now use valid to do test (cb)\n",
    "    test_nid2index = nid2index\n",
    "    test_news_index = news_index\n",
    "    test_sam = valid_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ctr(samples, news_click_count, news_impr_count, interval_time,):\n",
    "    for l in tqdm(samples):\n",
    "        pos, neg, his, uid, tsp = l\n",
    "        tsp = datetime.strptime(tsp,date_format_str)\n",
    "        tidx = int((tsp - start_time).total_seconds()/interval_time) \n",
    "        if type(pos) is list:\n",
    "            for i in pos:\n",
    "                nidx = nid2index[i]\n",
    "                news_click_count[nidx, tidx] += 1\n",
    "                news_impr_count[nidx, tidx] += 1\n",
    "        else:\n",
    "            nidx = nid2index[pos]\n",
    "            news_click_count[nidx, tidx] += 1\n",
    "            news_impr_count[nidx, tidx] += 1\n",
    "\n",
    "        for i in neg:\n",
    "            nidx = nid2index[i]\n",
    "            news_impr_count[nidx, tidx] += 1\n",
    "    return news_click_count, news_impr_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28604\n",
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34747/34747 [00:01<00:00, 25601.42it/s]\n",
      "100%|██████████| 7538/7538 [00:00<00:00, 30313.52it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interval_time = 3600\n",
    "start_time =  datetime.strptime(sorted_train_sam[0][-1],date_format_str)\n",
    "# print(start_time)\n",
    "end_time = datetime.strptime(valid_sam[-1][-1],date_format_str)\n",
    "nt = int((end_time - start_time).total_seconds()/interval_time) + 1 \n",
    "print(len(nid2index))\n",
    "print(nt)\n",
    "news_click_count = np.zeros((len(nid2index), nt), dtype=float)\n",
    "news_impr_count = np.ones((len(nid2index), nt), dtype=float) * 100 # assume 100 times init\n",
    "\n",
    "news_click_count, news_impr_count = cal_ctr(train_sam, news_click_count, news_impr_count, interval_time)\n",
    "news_click_count, news_impr_count = cal_ctr(valid_sam, news_click_count, news_impr_count, interval_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_ctr = np.zeros_like(news_click_count)\n",
    "# for i in tqdm(range(news_click_count.shape[0])):\n",
    "#     for j in range(news_click_count.shape[1]):\n",
    "#         if news_impr_count[i,j] == 0:\n",
    "#             assert news_click_count[i,j] == 0\n",
    "#             news_ctr[i,j] = 0\n",
    "#         else:\n",
    "#             news_ctr[i,j] = news_click_count[i,j]/news_impr_count[i,j]\n",
    "news_ctr = news_click_count/news_impr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# news_ctr = news_click_count/news_impr_count\n",
    "# plt.imshow(news_ctr[:,166])\n",
    "# plt.colorbar()\n",
    "tidx = 111\n",
    "nonzero = news_ctr[:,tidx][news_ctr[:, tidx] > 0]\n",
    "len(nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([29., 25., 33., 19., 11.,  7., 12., 18., 10.,  4.]),\n",
       " array([ 15. ,  38.5,  62. ,  85.5, 109. , 132.5, 156. , 179.5, 203. ,\n",
       "        226.5, 250. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nonzero_count = []\n",
    "for i in range(news_click_count.shape[1]):\n",
    "    nonzero = news_ctr[:,i][news_ctr[:, i] > 0]\n",
    "    nonzero_count.append(len(nonzero))\n",
    "plt.hist(nonzero_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsample(nnn, ratio):\n",
    "    if ratio > len(nnn):\n",
    "        return nnn + [\"<unk>\"] * (ratio - len(nnn))\n",
    "    else:\n",
    "        return random.sample(nnn, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, samples, nid2index, news_index):\n",
    "        self.news_index = news_index\n",
    "        self.nid2index = nid2index\n",
    "        self.samples = samples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # pos, neg, his, neg_his\n",
    "        pos, neg, his, uid, tsp = self.samples[idx]\n",
    "        neg = newsample(neg, npratio)\n",
    "        \n",
    "        candidate_news = [pos] + neg\n",
    "        # print('pos: ', pos)\n",
    "        # for n in candidate_news:\n",
    "        #     print(n)\n",
    "        #     print(self.nid2index[n])\n",
    "        if type(candidate_news[0]) is str:\n",
    "            assert candidate_news[0].startswith('N') # nid\n",
    "            candidate_news = self.news_index[[self.nid2index[n] for n in candidate_news]]\n",
    "        else: # nindex\n",
    "            candidate_news = self.news_index[[n for n in candidate_news]]\n",
    "        his = [self.nid2index[n] for n in his] + [0] * (max_his_len - len(his))\n",
    "        his = self.news_index[his]\n",
    "        \n",
    "        label = np.array(0)\n",
    "        return candidate_news, his, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_index):\n",
    "        self.news_index = news_index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.news_index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.news_index[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = NewsDataset(news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 samples,\n",
    "                 news_vecs,\n",
    "                 nid2index):\n",
    "        self.samples = samples\n",
    "        self.news_vecs = news_vecs\n",
    "        self.nid2index = nid2index\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        poss, negs, his, uid, tsp = self.samples[idx]\n",
    "        his = [self.nid2index[n] for n in his] + [0] * (max_his_len - len(his))\n",
    "        his = self.news_vecs[his]\n",
    "        return his, tsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True)  + 1e-8)\n",
    "        \n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model # 300\n",
    "        self.n_heads = n_heads # 20\n",
    "        self.d_k = d_k # 20\n",
    "        self.d_v = d_v # 20\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads) # 300, 400\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "                \n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1).expand(batch_size, max_len, max_len) \n",
    "            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "        \n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s, attn_mask) \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) \n",
    "        return context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    ''' AttentionPooling used to weighted aggregate news vectors\n",
    "    Arg: \n",
    "        d_h: the last dimension of input\n",
    "    '''\n",
    "    def __init__(self, d_h, hidden_size=200):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(d_h, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, candidate_vector_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, candidate_vector_dim\n",
    "        \"\"\"\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "\n",
    "        alpha = torch.exp(alpha)\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha)\n",
    "        x = torch.reshape(x, (bz, -1))  # (bz, 400)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 word_embedding_dim=300, \n",
    "                 num_attention_heads=20,\n",
    "                 query_vector_dim = 200,\n",
    "                 dropout_rate=0.2,\n",
    "                 enable_gpu=True):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.dropout_rate = 0.2\n",
    "        pretrained_news_word_embedding = torch.from_numpy(embedding_matrix).float()\n",
    "        \n",
    "        self.word_embedding = nn.Embedding.from_pretrained(\n",
    "            pretrained_news_word_embedding, freeze=False)\n",
    "        \n",
    "        self.multihead_attention = MultiHeadAttention(word_embedding_dim,\n",
    "                                              num_attention_heads, 20, 20)\n",
    "        self.additive_attention = AdditiveAttention(num_attention_heads*20,\n",
    "                                                    query_vector_dim)\n",
    "    def forward(self, text):\n",
    "        # REVIEW: remove training=self.training to enable dropout during testing \n",
    "        text_vector = F.dropout(self.word_embedding(text.long()),\n",
    "                                p=self.dropout_rate,\n",
    "                                # training=self.training\n",
    "                                )\n",
    "        multihead_text_vector = self.multihead_attention(\n",
    "            text_vector, text_vector, text_vector)\n",
    "        multihead_text_vector = F.dropout(multihead_text_vector,\n",
    "                                          p=self.dropout_rate,\n",
    "                                        #   training=self.training\n",
    "                                          )\n",
    "        # batch_size, word_embedding_dim\n",
    "        text_vector = self.additive_attention(multihead_text_vector)\n",
    "        return text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 news_embedding_dim=400,\n",
    "                 num_attention_heads=20,\n",
    "                 query_vector_dim=200\n",
    "                ):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        self.multihead_attention = MultiHeadAttention(news_embedding_dim,\n",
    "                                              num_attention_heads, 20, 20)\n",
    "        self.additive_attention = AdditiveAttention(num_attention_heads*20,\n",
    "                                                    query_vector_dim)\n",
    "        \n",
    "        self.neg_multihead_attention = MultiHeadAttention(news_embedding_dim,\n",
    "                                                         num_attention_heads, 20, 20)\n",
    "        \n",
    "    def forward(self, clicked_news_vecs):\n",
    "        multi_clicked_vectors = self.multihead_attention(\n",
    "            clicked_news_vecs, clicked_news_vecs, clicked_news_vecs\n",
    "        )\n",
    "        pos_user_vector = self.additive_attention(multi_clicked_vectors)\n",
    "        \n",
    "        user_vector = pos_user_vector\n",
    "        return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRMS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NRMS, self).__init__()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.user_encoder = UserEncoder()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, candidate_news, clicked_news, targets, compute_loss=True):\n",
    "        batch_size, npratio, word_num = candidate_news.shape\n",
    "        candidate_news = candidate_news.view(-1, word_num)\n",
    "        candidate_vector = self.text_encoder(candidate_news).view(batch_size, npratio, -1)\n",
    "        \n",
    "        batch_size, clicked_news_num, word_num = clicked_news.shape\n",
    "        clicked_news = clicked_news.view(-1, word_num)\n",
    "        clicked_news_vecs = self.text_encoder(clicked_news).view(batch_size, clicked_news_num, -1)\n",
    "        \n",
    "        user_vector = self.user_encoder(clicked_news_vecs)\n",
    "        \n",
    "        score = torch.bmm(candidate_vector, user_vector.unsqueeze(-1)).squeeze(dim=-1)\n",
    "        \n",
    "        if compute_loss:\n",
    "            loss = self.criterion(score, targets)\n",
    "            return loss, score\n",
    "        else:\n",
    "            return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amn(y_true, y_score):\n",
    "    auc = roc_auc_score(y_true,y_score)\n",
    "    mrr = mrr_score(y_true,y_score)\n",
    "    ndcg5 = ndcg_score(y_true,y_score,5)\n",
    "    ndcg10 = ndcg_score(y_true,y_score,10)\n",
    "    return auc, mrr, ndcg5, ndcg10\n",
    "\n",
    "def evaluation_split(news_vecs, user_vecs, samples, nid2index):\n",
    "    all_rslt = []\n",
    "    for i in tqdm(range(len(samples))):\n",
    "        poss, negs, _, _, _ = samples[i]\n",
    "        user_vec = user_vecs[i]\n",
    "        y_true = [1] * len(poss) + [0] * len(negs)\n",
    "        news_ids = [nid2index[i] for i in poss + negs]\n",
    "        news_vec = news_vecs[news_ids]\n",
    "        y_score = np.multiply(news_vec, user_vec)\n",
    "        y_score = np.sum(y_score, axis=1)\n",
    "        try:\n",
    "            all_rslt.append(compute_amn(y_true, y_score))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return np.array(all_rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TrainDataset(train_sam, nid2index, news_index)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    for time in range(1):\n",
    "        model = NRMS().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        best_auc = 0\n",
    "        for ep in range(epoch):\n",
    "            loss = 0\n",
    "            accuary = 0.0\n",
    "            model.train()\n",
    "            train_loader = tqdm(train_dl)\n",
    "            for cnt, batch_sample in enumerate(train_loader):\n",
    "                candidate_news_index, his_index, label = batch_sample\n",
    "                sample_num = candidate_news_index.shape[0]\n",
    "                candidate_news_index = candidate_news_index.to(device)\n",
    "                his_index = his_index.to(device)\n",
    "                label = label.to(device)\n",
    "                bz_loss, y_hat = model(candidate_news_index, his_index, label)\n",
    "\n",
    "                loss += bz_loss.detach().cpu().numpy()\n",
    "                optimizer.zero_grad()\n",
    "                bz_loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                if cnt % 10 == 0:\n",
    "                    train_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                    train_loader.refresh() \n",
    "\n",
    "\n",
    "            model.eval()\n",
    "            news_dl = DataLoader(news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(valid_sam, news_vecs, nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            for his, tsp in tqdm(user_dl):\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            val_scores = evaluation_split(news_vecs, user_vecs, valid_sam, nid2index)\n",
    "            val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*val_scores))]\n",
    "            print(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\")\n",
    "\n",
    "            with open(model_path/f'{name}.txt', 'a') as f:\n",
    "                f.write(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "                    \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                torch.save(model.state_dict(), model_path/f'{name}.pkl')\n",
    "                with open(model_path/f'{name}.txt', 'a') as f:\n",
    "                    f.write(f\"[{ep}] epoch save model\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eva_metric(y_scores, y_trues):\n",
    "    all_rslt_mean = []\n",
    "    all_rslt_ucb1 = []\n",
    "    all_rslt_ucb05 = []\n",
    "    all_rslt_ucb15 = []\n",
    "\n",
    "    for key, value in y_scores.items():\n",
    "        mean = np.asarray(value).mean(axis = 0)\n",
    "        std = np.asarray(value).std(axis = 0)\n",
    "        # print(utc.metrics.get_all_metrics(mean, std, np.array(y_trues[key])))\n",
    "        try:\n",
    "            all_rslt_mean.append(compute_amn(y_trues[key], mean))\n",
    "            all_rslt_ucb1.append(compute_amn(y_trues[key], mean + std ))\n",
    "            all_rslt_ucb05.append(compute_amn(y_trues[key], mean + 0.5 * std ))\n",
    "            all_rslt_ucb15.append(compute_amn(y_trues[key], mean + 1.5 * std ))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_mean)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 0 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "\n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb05)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 0.5 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "        \n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb1)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 1 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "   \n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb15)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 1.5 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offline \n",
    "\n",
    "if offline_flag:\n",
    "    model = NRMS().to(device)\n",
    "    model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "    model.eval()\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('dropout'):\n",
    "            print(m)\n",
    "            m.train()\n",
    "\n",
    "    y_scores = defaultdict(list)\n",
    "    y_trues = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in tqdm(range(eva_times)):\n",
    "            test_news_dataset = NewsDataset(test_news_index)\n",
    "            news_dl = DataLoader(test_news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(test_sam, news_vecs, test_nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            for his_tsp in tqdm(user_dl):\n",
    "                his, _ = his_tsp\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            for i in tqdm(range(len(valid_sam))):\n",
    "                poss, negs, _, _, _ = valid_sam[i]\n",
    "                user_vec = user_vecs[i]\n",
    "                y_true = [1] * len(poss) + [0] * len(negs)\n",
    "                news_ids = [nid2index[i] for i in poss + negs]\n",
    "                news_vec = news_vecs[news_ids]\n",
    "                y_score = np.multiply(news_vec, user_vec)\n",
    "                y_score = np.sum(y_score, axis=1)\n",
    "                \n",
    "                y_scores[i].append(y_score)\n",
    "                y_trues[i] = y_true\n",
    "\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"offline eva with eva : {eva_times} times\\n\")\n",
    "    print_eva_metric(y_scores, y_trues)\n",
    "\n",
    "    # test_auc, test_mrr, test_ndcg, test_ndcg10 = [np.mean(i) for i in list(zip(*test_scores))]\n",
    "    # print(f\"[{i}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\")\n",
    "\n",
    "# with open(model_path/ f'{name}.txt', 'a') as f:\n",
    "#         f.write(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_trainable_samples(samples):\n",
    "    tr_samples = []\n",
    "    for l in samples:\n",
    "        pos_imp, neg_imp, his, uid, tsp = l    \n",
    "        for pos in list(pos_imp):\n",
    "            tr_samples.append([pos, neg_imp, his, uid, tsp])\n",
    "    return tr_samples\n",
    "\n",
    "\n",
    "\n",
    "def finetune(model, ft_sam, nid2index, news_index, batch_size):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    ft_sam = construct_trainable_samples(ft_sam)\n",
    "    ft_ds = TrainDataset(ft_sam, nid2index, news_index)\n",
    "    ft_dl = DataLoader(ft_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    for ep in range(epoch):\n",
    "        loss = 0\n",
    "        accuary = 0.0\n",
    "        model.train()\n",
    "        ft_loader = tqdm(ft_dl)\n",
    "        for cnt, batch_sample in enumerate(ft_loader):\n",
    "            candidate_news_index, his_index, label = batch_sample\n",
    "            sample_num = candidate_news_index.shape[0]\n",
    "            candidate_news_index = candidate_news_index.to(device)\n",
    "            his_index = his_index.to(device)\n",
    "            label = label.to(device)\n",
    "            bz_loss, y_hat = model(candidate_news_index, his_index, label)\n",
    "\n",
    "            loss += bz_loss.detach().cpu().numpy()\n",
    "            optimizer.zero_grad()\n",
    "            bz_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if cnt % 10 == 0:\n",
    "                ft_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                ft_loader.refresh() \n",
    "\n",
    "    return model \n",
    "\n",
    "def eva_batch(model, droupout_flag, batch_news_index, batch_sam, batch_nid2index, y_scores, y_trues, ucbs, batch_size, batch_id):\n",
    "    model.eval()\n",
    "    if droupout_flag:\n",
    "        for m in model.modules():\n",
    "            if m.__class__.__name__.startswith('dropout'):\n",
    "                print(m)\n",
    "                m.train()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(eva_times)):\n",
    "            batch_news_dataset = NewsDataset(batch_news_index)\n",
    "            news_dl = DataLoader(batch_news_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(batch_sam, news_vecs, batch_nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "\n",
    "            for his_tsp in tqdm(user_dl):\n",
    "                his, tsp = his_tsp\n",
    "                batch_time = datetime.strptime(str(tsp[-1]), date_format_str)\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "                # print(tsp)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            start_id = batch_size * batch_id\n",
    "\n",
    "            for i in tqdm(range(len(batch_sam))):\n",
    "                poss, negs, _, _,_ = batch_sam[i]\n",
    "                user_vec = user_vecs[i]\n",
    "                y_true = [1] * len(poss) + [0] * len(negs)\n",
    "                news_ids = [nid2index[i] for i in poss + negs]\n",
    "                news_vec = news_vecs[news_ids]\n",
    "                y_score = np.multiply(news_vec, user_vec)\n",
    "                y_score = np.sum(y_score, axis=1)\n",
    "                \n",
    "                y_scores[start_id+i].append(y_score)\n",
    "                y_trues[start_id+i] = y_true\n",
    "                \n",
    "    return y_scores, y_trues, batch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# online \n",
    "\n",
    "if online_flag:\n",
    "\n",
    "    print('online eva')\n",
    "\n",
    "    model = NRMS().to(device)\n",
    "    model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "\n",
    "    y_scores = defaultdict(list)\n",
    "    y_trues = {}\n",
    "\n",
    "    update_time = None\n",
    "    update_batch = 0\n",
    "    batch_size = 1024\n",
    "    dropout_flag = True\n",
    "\n",
    "    n_batch = math.ceil(float(len(test_sam))/batch_size)\n",
    "\n",
    "    for i in range(n_batch):\n",
    "        upper_range = min(1024 * (i+1), len(test_sam))\n",
    "        batch_sam = test_sam[1024 * i: upper_range]\n",
    "\n",
    "        y_scores, y_trues, batch_time = eva_batch(model, dropout_flag, test_news_index, batch_sam, test_nid2index, y_scores, y_trues, batch_size, i)\n",
    "        \n",
    "        num_sample = len(y_scores)\n",
    "        with open(model_path/f'{name}.txt', 'a') as f:\n",
    "            f.write(f\"online eva on batch : {i} with {num_sample} samples in current batch, up to index {upper_range}\\n\")\n",
    "        print_eva_metric(y_scores, y_trues)\n",
    "    \n",
    "        if update_time is None:\n",
    "            update_time = batch_time\n",
    "            print('init update time: ', update_time)\n",
    "        if (batch_time- update_time).total_seconds() > 3600:\n",
    "\n",
    "            ft_sam = test_sam[1024 * update_batch: upper_range]\n",
    "            if upper_range - 1024 * update_batch > 512:\n",
    "                print('finetune with: '  + str(1024 * update_batch) + ' ~ ' + str(upper_range))\n",
    "                model = finetune(model=model, ft_sam=ft_sam, nid2index=test_nid2index, news_index=test_news_index, batch_size=32)\n",
    "\n",
    "                update_time = batch_time\n",
    "                update_batch = i + 1\n",
    "                print('update before: ', update_time)\n",
    "            else: \n",
    "                print('no finetune due to insufficient samples: ', str(upper_range - 1024 * update_batch))\n",
    "\n",
    "    torch.save(model.state_dict(), model_path/f'{name}_finetune.pkl')\n",
    "# sys.stdout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandit Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CB_sim():\n",
    "    def __init__(\n",
    "        self, model_path, simulator_path, out_path, device,\n",
    "        news_index, nid2index,\n",
    "        finetune_batch_size = 32, eva_batch_size = 1024, dropout_flag = True, n_inference = 50, policy = 'ucb'\n",
    "    ):\n",
    "        self.model = NRMS().to(device)\n",
    "        self.model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "        \n",
    "        # TODO: change simulator to PLM\n",
    "        self.simulator = NRMS().to(device)\n",
    "        self.simulator.load_state_dict(torch.load(simulator_path/f'{name}.pkl'))\n",
    "\n",
    "        self.news_index = news_index\n",
    "        self.nid2index = nid2index\n",
    "\n",
    "        self.out_path = out_path\n",
    "        self.dropout_flag = dropout_flag\n",
    "        self.n_inference = n_inference\n",
    "        self.finetune_batch_size = finetune_batch_size\n",
    "        self.eva_batch_size = eva_batch_size\n",
    "        self.date_format_str = '%m/%d/%Y %I:%M:%S %p'\n",
    "\n",
    "        self.policy = policy\n",
    "\n",
    "    \n",
    "    def enable_dropout(self):\n",
    "        for m in self.model.modules():\n",
    "            if m.__class__.__name__.startswith('dropout'):\n",
    "                print(m)\n",
    "                m.train() \n",
    "        \n",
    "    def get_news_vec(self, model, batch_news_index):\n",
    "        batch_news_dataset = NewsDataset(batch_news_index)\n",
    "        news_dl = DataLoader(batch_news_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        news_vecs = []\n",
    "        for news in tqdm(news_dl):\n",
    "            news = news.to(device)\n",
    "            news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "            news_vecs.append(news_vec)\n",
    "        news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "        return news_vecs\n",
    "\n",
    "    def get_user_vec(self, model, batch_sam, news_vecs, batch_nid2index):\n",
    "        user_dataset = UserDataset(batch_sam, news_vecs, batch_nid2index)\n",
    "        user_vecs = []\n",
    "        user_dl = DataLoader(user_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        for his_tsp in tqdm(user_dl):\n",
    "            his, tsp = his_tsp\n",
    "            his = his.to(device)\n",
    "            user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "            user_vecs.append(user_vec)\n",
    "            # print(tsp)\n",
    "        user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "        return user_vecs\n",
    "        \n",
    "    def get_cand_news(self, t, poss, negs, m = 10):\n",
    "        \"\"\"\n",
    "        Generate candidates news based on CTR.\n",
    "\n",
    "        t: string, impr time\n",
    "        poss: list, positive samples in impr\n",
    "        negs: list, neg samples in impr\n",
    "        m: int, number of candidate news to return\n",
    "\n",
    "        Return: array, candidate news id \n",
    "        \"\"\"\n",
    "        t = datetime.strptime(t,date_format_str)\n",
    "        tidx = int((t - start_time).total_seconds()/interval_time)\n",
    "\n",
    "        nonzero = news_ctr[:,tidx -1][news_ctr[:, tidx-1] > 0]\n",
    "        nonzero_idx = np.where(news_ctr[:, tidx-1] > 0)[0]\n",
    "        # print(nonzero_idx)\n",
    "\n",
    "        nonzero = nonzero/nonzero.sum()\n",
    "        assert (nonzero.sum() - 1) < 1e-3\n",
    "        # print(np.sort(nonzero)[-5:])\n",
    "\n",
    "        # sampling according to normalised ctr in last one hour\n",
    "        sample_nids = np.random.choice(nonzero_idx, size = m, replace = False, p = nonzero)\n",
    "        # REVIEW: check whether the sampled nids are reasonable\n",
    "        \n",
    "        # print(news_ctr[sample_nidx, tidx-1])\n",
    "        # plt.hist(nonzero)\n",
    "        # print(poss)\n",
    "        # print(negs)\n",
    "        poss_nids = np.array([self.nid2index[n] for n in poss])\n",
    "        negs_nids = np.array([self.nid2index[n] for n in negs])\n",
    "        # print('get cand news')\n",
    "        # print(sample_nids)\n",
    "        # print(poss_nids)\n",
    "        # print(negs_nids)\n",
    "\n",
    "        return np.concatenate([sample_nids, poss_nids, negs_nids])\n",
    "        \n",
    "#     t =  sorted_train_sam[1500][-1]\n",
    "#     gene_news_pool(t, 20)\n",
    "\n",
    "    def construct_trainable_samples(self, samples):\n",
    "        tr_samples = []\n",
    "        for l in samples:\n",
    "            pos_imp, neg_imp, his, uid, tsp = l    \n",
    "            for pos in list(pos_imp):\n",
    "                tr_samples.append([pos, neg_imp, his, uid, tsp])\n",
    "        return tr_samples\n",
    "\n",
    "    def finetune(self, ft_sam):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        ft_sam = self.construct_trainable_samples(ft_sam)\n",
    "        ft_ds = TrainDataset(ft_sam, self.nid2index, self.news_index)\n",
    "        ft_dl = DataLoader(ft_ds, batch_size=self.finetune_batch_size, shuffle=True, num_workers=0)\n",
    "        for ep in range(epoch):\n",
    "            loss = 0\n",
    "            accuary = 0.0\n",
    "            self.model.train()\n",
    "            ft_loader = tqdm(ft_dl)\n",
    "            for cnt, batch_sample in enumerate(ft_loader):\n",
    "                candidate_news_index, his_index, label = batch_sample\n",
    "                sample_num = candidate_news_index.shape[0]\n",
    "                candidate_news_index = candidate_news_index.to(device)\n",
    "                his_index = his_index.to(device)\n",
    "                label = label.to(device)\n",
    "                bz_loss, y_hat = self.model(candidate_news_index, his_index, label)\n",
    "\n",
    "                loss += bz_loss.detach().cpu().numpy()\n",
    "                optimizer.zero_grad()\n",
    "                bz_loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                if cnt % 10 == 0:\n",
    "                    ft_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                    ft_loader.refresh() \n",
    "\n",
    "    def get_ucb_score(self, exper_id, y_score, t):\n",
    "        ucb = []\n",
    "        beta_t = 1\n",
    "\n",
    "        mean = np.asarray(y_score).mean(axis = 0)\n",
    "        std = np.asarray(y_score).std(axis = 0)\n",
    "        ucb_score = mean + beta_t * std\n",
    "\n",
    "        rec_nids = np.argsort(ucb_score)[-k:]\n",
    "        return rec_nids\n",
    "\n",
    "    def epsilon_greedy(self, exper_id, y_score, k, epsilon = 0.1):\n",
    "        rec = []\n",
    "        y_score = y_score[0]\n",
    "        p = np.random.rand(k)\n",
    "        n_greedy = int(len(p[p > epsilon]))\n",
    "        greedy_nids = np.argsort(y_score)[-n_greedy:]\n",
    "        eps_nids = np.random.choice(np.array(list(set(range(len(y_score))) - set(greedy_nids))), size = k - n_greedy, replace=False)\n",
    "        rec_nids= np.concatenate([greedy_nids, eps_nids])\n",
    "        return rec_nids\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return np.array([1/(1 + math.exp(-i)) for i in x])\n",
    "                \n",
    "    def rec(self, batch_sam, batch_id, exper_id, k = 8):\n",
    "        \"\"\"\n",
    "        Simulate recommendations\n",
    "        \"\"\"\n",
    "        if self.policy == 'epsilon_greedy':\n",
    "            self.n_inference = 1\n",
    "        \n",
    "        self.model.eval()\n",
    "        if self.dropout_flag:\n",
    "            self.enable_dropout()\n",
    "\n",
    "        y_scores = defaultdict(list) # key: sam_id, value: list of n_inference scores \n",
    "        cand_nids_dict = {} # key: sam_id, value: array of candidate news ids\n",
    "        start_id = self.eva_batch_size * batch_id\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sim_news_vecs = self.get_news_vec(self.simulator, self.news_index)\n",
    "            sim_user_vecs = self.get_user_vec(self.simulator, batch_sam, sim_news_vecs, self.nid2index) \n",
    "\n",
    "            # generate scores with uncertainty (dropout during inference)\n",
    "            for _ in tqdm(range(self.n_inference)):\n",
    "                # TODO: speed up - only pass batch news index\n",
    "                news_vecs = self.get_news_vec(self.model, self.news_index)\n",
    "                user_vecs = self.get_user_vec(self.model, batch_sam, news_vecs, self.nid2index)\n",
    "                \n",
    "                for i in tqdm(range(len(batch_sam))):\n",
    "                    t = start_id + i\n",
    "                    poss, negs, his, uid, tsq = batch_sam[i]     \n",
    "                    user_vec = user_vecs[i]\n",
    "                    \n",
    "                    if t not in cand_nids_dict.keys():\n",
    "                        # cand set (is a randomised set) keeps same for inference times\n",
    "                        cand_nids = self.get_cand_news(tsq, poss, negs)\n",
    "                        cand_nids_dict[t] = cand_nids\n",
    "                        # print(cand_nids)\n",
    "                        news_vec = news_vecs[cand_nids]\n",
    "                        sim_user_vec = sim_user_vecs[i]\n",
    "                        sim_news_vec = sim_news_vecs[cand_nids]\n",
    "                        sim_y_score = np.sum(np.multiply(sim_news_vec, sim_user_vec), axis=1)\n",
    "                        # assume the user would at most click half of the recommended news\n",
    "                        opt_nids = np.argsort(sim_y_score)[-int(k/2):] \n",
    "                        # print(opt_nids)\n",
    "                        # print(self.sigmoid(sim_y_score[opt_nids]))\n",
    "                        opt_nids = opt_nids[self.sigmoid(sim_y_score[opt_nids]) > 0.5]\n",
    "                        # print(opt_nids)\n",
    "                        self.opts[exper_id].append(opt_nids)   \n",
    "                    \n",
    "                    news_vec = news_vecs[cand_nids_dict[t]]\n",
    "                    y_score = np.sum(np.multiply(news_vec, user_vec), axis=1)\n",
    "                    y_scores[t].append(y_score)\n",
    "\n",
    "        # generate recommendations and calculate rewards\n",
    "        for i in tqdm(range(len(batch_sam))):\n",
    "            t = start_id + i\n",
    "            _, _, his, uid, tsq = batch_sam[i]  \n",
    "\n",
    "            if self.policy == 'ucb':\n",
    "                rec_nids = self.get_ucb_score(exper_id, y_scores[t], t)\n",
    "            elif self.policy == 'epsilon_greedy':\n",
    "                rec_nids = self.epsilon_greedy(exper_id, y_scores[t], k)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            self.recs[exper_id].append(rec_nids) \n",
    "            \n",
    "            opt_nids = self.opts[exper_id][i]\n",
    " \n",
    "            assert len(set(rec_nids)) == k\n",
    "            # assert len(set(opt_nids)) == k\n",
    "\n",
    "            reward = len(set(rec_nids) & set(opt_nids)) # reward as the overlap between rec and opt set\n",
    "            # self.cumu_reward += reward\n",
    "            self.rewards[exper_id, t] = reward\n",
    "            self.opt_rewards[exper_id, t] = len(set(opt_nids))\n",
    "\n",
    "            rec_poss = [rec_nid for rec_nid in rec_nids if rec_nid in opt_nids]\n",
    "            # let all \n",
    "            rec_negs = list(set(cand_nids_dict[t]) - set(rec_poss))\n",
    "            \n",
    "            self.rec_sam.append([rec_poss, rec_negs, his, uid, tsq])\n",
    "        \n",
    "    def run_exper(self, test_sam, num_exper = 10):\n",
    "        num_sam = len(test_sam)\n",
    "        n_batch = math.ceil(float(num_sam)/self.eva_batch_size)\n",
    "        self.rec_sam = []\n",
    "        self.rewards = np.zeros((num_exper, num_sam))\n",
    "        self.opt_rewards = np.zeros((num_exper, num_sam))\n",
    "        self.recs = defaultdict(list)\n",
    "        self.opts = defaultdict(list)\n",
    "        update_time = None\n",
    "        update_batch = 0\n",
    "        \n",
    "\n",
    "        for j in range(num_exper):\n",
    "            # self.cumu_reward = 0\n",
    "            \n",
    "            for i in range(n_batch):\n",
    "                upper_range = min(self.eva_batch_size * (i+1), len(test_sam))\n",
    "                batch_sam = test_sam[self.eva_batch_size * i: upper_range]\n",
    "\n",
    "                self.rec(batch_sam, i, j)\n",
    "\n",
    "                if update_time is None:\n",
    "                    update_time = datetime.strptime(str(batch_sam[0][-1]), self.date_format_str)\n",
    "                    print('init time: ', update_time)\n",
    "\n",
    "                batch_time = datetime.strptime(str(batch_sam[-1][-1]), self.date_format_str)\n",
    "                if (batch_time- update_time).total_seconds() > 3600:\n",
    "                    lower_range = self.eva_batch_size * update_batch\n",
    "                    ft_sam = self.rec_sam[lower_range: upper_range]\n",
    "                    if upper_range - lower_range > 512:\n",
    "                        print('finetune with: '  + str(lower_range) + ' ~ ' + str(upper_range))\n",
    "                        self.finetune(ft_sam=ft_sam)\n",
    "\n",
    "                        update_time = batch_time\n",
    "                        update_batch = i + 1\n",
    "                        print('update at: ', update_time)\n",
    "                    else: \n",
    "                        print('no finetune due to insufficient samples: ', str(upper_range - lower_range))\n",
    "\n",
    "        self.save_results()\n",
    "\n",
    "    def save_results(self):\n",
    "        torch.save(self.model.state_dict(), model_path/f'{name}_finetune.pkl')\n",
    "        with open(os.path.join(self.out_path, \"recs.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.recs, f)\n",
    "        with open(os.path.join(self.out_path, \"opts.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.opts, f)\n",
    "        with open(os.path.join(self.out_path, \"rewards.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.rewards, f)\n",
    "        with open(os.path.join(self.out_path, \"opt_rewards.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.opt_rewards, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:05<00:00, 175.56it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 265.87it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 178.90it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 288.44it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1999.54it/s]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.43s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11137.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init time:  2019-11-15 00:00:13\n",
      "finetune with: 0 ~ 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[90]steps loss: 1.3307 : 100%|██████████| 93/93 [00:10<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update at:  2019-11-15 05:39:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:04<00:00, 179.20it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 257.71it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 179.21it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 210.55it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 2078.77it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.66s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11504.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune with: 1024 ~ 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10]steps loss: 0.6838 : 100%|██████████| 20/20 [00:02<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update at:  2019-11-15 07:19:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:05<00:00, 175.77it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 245.15it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 178.93it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 304.82it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1924.25it/s]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11182.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune with: 2048 ~ 3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10]steps loss: 0.4469 : 100%|██████████| 18/18 [00:01<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update at:  2019-11-15 08:49:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:05<00:00, 177.68it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 289.83it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 178.79it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 294.12it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1977.12it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.90s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11190.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune with: 3072 ~ 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10]steps loss: 0.3100 : 100%|██████████| 18/18 [00:01<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update at:  2019-11-15 10:20:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:04<00:00, 179.32it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 293.45it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 178.84it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 275.72it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1966.97it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.66s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11238.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune with: 4096 ~ 5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10]steps loss: 0.2330 : 100%|██████████| 19/19 [00:02<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update at:  2019-11-15 11:53:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:05<00:00, 178.40it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 235.76it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 177.18it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 284.93it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1667.83it/s]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.10s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 10399.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune with: 5120 ~ 6144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10]steps loss: 0.1807 : 100%|██████████| 20/20 [00:02<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update at:  2019-11-15 13:39:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:05<00:00, 178.79it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 295.89it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 177.63it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 298.01it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1946.90it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.82s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11058.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune with: 6144 ~ 7168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10]steps loss: 0.1941 : 100%|██████████| 19/19 [00:02<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update at:  2019-11-15 16:43:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:04<00:00, 178.98it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 305.68it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 178.64it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 307.79it/s]\n",
      "100%|██████████| 370/370 [00:00<00:00, 1943.91it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.30s/it]\n",
      "100%|██████████| 370/370 [00:00<00:00, 10778.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no finetune due to insufficient samples:  370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:04<00:00, 179.28it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 295.45it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 177.51it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 293.20it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 2065.53it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.67s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11205.88it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 179.11it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 291.92it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 177.73it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 235.89it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1961.16it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.74s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 10394.68it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 180.11it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 272.13it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 179.77it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 311.55it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1998.77it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11209.21it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 179.07it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 299.35it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 177.92it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 292.81it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 1942.71it/s]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.70s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11294.70it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 175.41it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 263.65it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 176.40it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 306.62it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 2101.85it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.69s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11302.72it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 176.95it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 301.39it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 181.19it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 284.47it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 2076.11it/s]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.22s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 11076.58it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 175.16it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 310.79it/s]\n",
      "100%|██████████| 894/894 [00:05<00:00, 177.99it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 308.14it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 2010.83it/s]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.25s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 10662.46it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 178.86it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 284.50it/s]\n",
      "100%|██████████| 894/894 [00:04<00:00, 179.50it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 296.32it/s]\n",
      "100%|██████████| 370/370 [00:00<00:00, 1984.13it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.29s/it]\n",
      "100%|██████████| 370/370 [00:00<00:00, 11117.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no finetune due to insufficient samples:  370\n"
     ]
    }
   ],
   "source": [
    "cb_sim = CB_sim(model_path=model_path, simulator_path=model_path, out_path=model_path, device=device, news_index=test_news_index, nid2index=test_nid2index, n_inference = 2, policy='epsilon_greedy')\n",
    "cb_sim.run_exper(test_sam=test_sam, num_exper=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exper, num_sam = cb_sim.rewards.shape\n",
    "cumu_regrets = np.zeros((num_exper, num_sam))\n",
    "for i in range(num_exper):\n",
    "    cumu_reward = 0\n",
    "    cumu_opt_reward = 0\n",
    "\n",
    "    for j in range(num_sam):\n",
    "        cumu_reward += cb_sim.rewards[i,j]\n",
    "        cumu_opt_reward += cb_sim.opt_rewards[i,j]\n",
    "        cumu_regrets[i,j] = (cumu_opt_reward - cumu_reward)/(j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1a514a1438>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(num_sam), cumu_regrets.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2404., 2003., 1365.,  841.,    0.,  573.,  245.,   90.,   14.,\n",
       "           3.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cb_sim.rewards.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  38.,  139.,  363.,  466.,    0.,  596.,  677.,  662.,  658.,\n",
       "        3939.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cb_sim.opt_rewards.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
