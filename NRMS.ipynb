{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import copy\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "from datetime import datetime \n",
    "import math\n",
    "import uncertainty_toolbox as utc\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "from model import NRMS\n",
    "from dataloader import TrainDataset, NewsDataset, UserDataset\n",
    "from policy import CB_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'demo/'\n",
    "\n",
    "data_path = Path(\"/home/v-mezhang/blob/data/\" + str(dataset) + \"utils/\")\n",
    "model_path = Path(\"/home/v-mezhang/blob/model/\" + str(dataset))\n",
    "\n",
    "date_format_str = '%m/%d/%Y %I:%M:%S %p'\n",
    "\n",
    "# sys.stdout = open(model_path / 'output.txt', \"w\")\n",
    "# print(model_path)\n",
    "# sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "npratio = 4\n",
    "max_his_len = 50\n",
    "min_word_cnt = 3\n",
    "max_title_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch = 1\n",
    "lr=0.0001\n",
    "name = 'nrms_' + dataset[:-1]\n",
    "retrain = False\n",
    "online_flag = False\n",
    "offline_flag = False\n",
    "cb_flag = True\n",
    "eva_times = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'train_sam_uid.pkl', 'rb') as f:\n",
    "    train_sam = pickle.load(f)\n",
    "\n",
    "with open(data_path/'sorted_train_sam_uid.pkl', 'rb') as f:\n",
    "    sorted_train_sam = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'sorted_valid_sam_uid.pkl', 'rb') as f:\n",
    "    valid_sam = pickle.load(f)\n",
    "\n",
    "if os.path.exists(data_path/'test_sam_uid.pkl'):    \n",
    "    with open(data_path/'test_sam_uid.pkl', 'rb') as f:\n",
    "        test_sam = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'nid2index.pkl', 'rb') as f:\n",
    "    nid2index = pickle.load(f)\n",
    "    \n",
    "with open(data_path/'vocab_dict.pkl', 'rb') as f:\n",
    "    vocab_dict = pickle.load(f)\n",
    "\n",
    "embedding_matrix = np.load(data_path/'embedding.npy')\n",
    "news_index = np.load(data_path /'news_index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(data_path/'test_nid2index.pkl'):\n",
    "    with open(data_path/'test_nid2index.pkl', 'rb') as f:\n",
    "        test_nid2index = pickle.load(f)\n",
    "\n",
    "    test_news_index = np.load(data_path /'test_news_index.npy')\n",
    "else: # TODO: for now use valid to do test (cb)\n",
    "    test_nid2index = nid2index\n",
    "    test_news_index = news_index\n",
    "    test_sam = valid_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ctr(samples, news_click_count, news_impr_count, interval_time,):\n",
    "    for l in tqdm(samples):\n",
    "        pos, neg, his, uid, tsp = l\n",
    "        tsp = datetime.strptime(tsp,date_format_str)\n",
    "        tidx = int((tsp - start_time).total_seconds()/interval_time) \n",
    "        if type(pos) is list:\n",
    "            for i in pos:\n",
    "                nidx = nid2index[i]\n",
    "                news_click_count[nidx, tidx] += 1\n",
    "                news_impr_count[nidx, tidx] += 1\n",
    "        else:\n",
    "            nidx = nid2index[pos]\n",
    "            news_click_count[nidx, tidx] += 1\n",
    "            news_impr_count[nidx, tidx] += 1\n",
    "\n",
    "        for i in neg:\n",
    "            nidx = nid2index[i]\n",
    "            news_impr_count[nidx, tidx] += 1\n",
    "    return news_click_count, news_impr_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28604\n",
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34747/34747 [00:01<00:00, 26843.91it/s]\n",
      "100%|██████████| 7538/7538 [00:00<00:00, 31213.05it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interval_time = 3600\n",
    "start_time =  datetime.strptime(sorted_train_sam[0][-1],date_format_str)\n",
    "# print(start_time)\n",
    "end_time = datetime.strptime(valid_sam[-1][-1],date_format_str)\n",
    "nt = int((end_time - start_time).total_seconds()/interval_time) + 1 \n",
    "print(len(nid2index))\n",
    "print(nt)\n",
    "news_click_count = np.zeros((len(nid2index), nt), dtype=float)\n",
    "news_impr_count = np.ones((len(nid2index), nt), dtype=float) * 100 # assume 100 times init\n",
    "\n",
    "news_click_count, news_impr_count = cal_ctr(train_sam, news_click_count, news_impr_count, interval_time)\n",
    "news_click_count, news_impr_count = cal_ctr(valid_sam, news_click_count, news_impr_count, interval_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_ctr = np.zeros_like(news_click_count)\n",
    "# for i in tqdm(range(news_click_count.shape[0])):\n",
    "#     for j in range(news_click_count.shape[1]):\n",
    "#         if news_impr_count[i,j] == 0:\n",
    "#             assert news_click_count[i,j] == 0\n",
    "#             news_ctr[i,j] = 0\n",
    "#         else:\n",
    "#             news_ctr[i,j] = news_click_count[i,j]/news_impr_count[i,j]\n",
    "news_ctr = news_click_count/news_impr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# news_ctr = news_click_count/news_impr_count\n",
    "# plt.imshow(news_ctr[:,166])\n",
    "# plt.colorbar()\n",
    "tidx = 111\n",
    "nonzero = news_ctr[:,tidx][news_ctr[:, tidx] > 0]\n",
    "len(nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([29., 25., 33., 19., 11.,  7., 12., 18., 10.,  4.]),\n",
       " array([ 15. ,  38.5,  62. ,  85.5, 109. , 132.5, 156. , 179.5, 203. ,\n",
       "        226.5, 250. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nonzero_count = []\n",
    "for i in range(news_click_count.shape[1]):\n",
    "    nonzero = news_ctr[:,i][news_ctr[:, i] > 0]\n",
    "    nonzero_count.append(len(nonzero))\n",
    "plt.hist(nonzero_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amn(y_true, y_score):\n",
    "    auc = roc_auc_score(y_true,y_score)\n",
    "    mrr = mrr_score(y_true,y_score)\n",
    "    ndcg5 = ndcg_score(y_true,y_score,5)\n",
    "    ndcg10 = ndcg_score(y_true,y_score,10)\n",
    "    return auc, mrr, ndcg5, ndcg10\n",
    "\n",
    "def evaluation_split(news_vecs, user_vecs, samples, nid2index):\n",
    "    all_rslt = []\n",
    "    for i in tqdm(range(len(samples))):\n",
    "        poss, negs, _, _, _ = samples[i]\n",
    "        user_vec = user_vecs[i]\n",
    "        y_true = [1] * len(poss) + [0] * len(negs)\n",
    "        news_ids = [nid2index[i] for i in poss + negs]\n",
    "        news_vec = news_vecs[news_ids]\n",
    "        y_score = np.multiply(news_vec, user_vec)\n",
    "        y_score = np.sum(y_score, axis=1)\n",
    "        try:\n",
    "            all_rslt.append(compute_amn(y_true, y_score))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return np.array(all_rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TrainDataset(train_sam, nid2index, news_index)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    for time in range(1):\n",
    "        model = NRMS().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        best_auc = 0\n",
    "        for ep in range(epoch):\n",
    "            loss = 0\n",
    "            accuary = 0.0\n",
    "            model.train()\n",
    "            train_loader = tqdm(train_dl)\n",
    "            for cnt, batch_sample in enumerate(train_loader):\n",
    "                candidate_news_index, his_index, label = batch_sample\n",
    "                sample_num = candidate_news_index.shape[0]\n",
    "                candidate_news_index = candidate_news_index.to(device)\n",
    "                his_index = his_index.to(device)\n",
    "                label = label.to(device)\n",
    "                bz_loss, y_hat = model(candidate_news_index, his_index, label)\n",
    "\n",
    "                loss += bz_loss.detach().cpu().numpy()\n",
    "                optimizer.zero_grad()\n",
    "                bz_loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                if cnt % 10 == 0:\n",
    "                    train_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                    train_loader.refresh() \n",
    "\n",
    "\n",
    "            model.eval()\n",
    "            news_dl = DataLoader(news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(valid_sam, news_vecs, nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            for his, tsp in tqdm(user_dl):\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            val_scores = evaluation_split(news_vecs, user_vecs, valid_sam, nid2index)\n",
    "            val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*val_scores))]\n",
    "            print(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\")\n",
    "\n",
    "            with open(model_path/f'{name}.txt', 'a') as f:\n",
    "                f.write(f\"[{ep}] epoch auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "                    \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                torch.save(model.state_dict(), model_path/f'{name}.pkl')\n",
    "                with open(model_path/f'{name}.txt', 'a') as f:\n",
    "                    f.write(f\"[{ep}] epoch save model\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eva_metric(y_scores, y_trues):\n",
    "    all_rslt_mean = []\n",
    "    all_rslt_ucb1 = []\n",
    "    all_rslt_ucb05 = []\n",
    "    all_rslt_ucb15 = []\n",
    "\n",
    "    for key, value in y_scores.items():\n",
    "        mean = np.asarray(value).mean(axis = 0)\n",
    "        std = np.asarray(value).std(axis = 0)\n",
    "        # print(utc.metrics.get_all_metrics(mean, std, np.array(y_trues[key])))\n",
    "        try:\n",
    "            all_rslt_mean.append(compute_amn(y_trues[key], mean))\n",
    "            all_rslt_ucb1.append(compute_amn(y_trues[key], mean + std ))\n",
    "            all_rslt_ucb05.append(compute_amn(y_trues[key], mean + 0.5 * std ))\n",
    "            all_rslt_ucb15.append(compute_amn(y_trues[key], mean + 1.5 * std ))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_mean)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 0 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "\n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb05)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 0.5 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "        \n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb1)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 1 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n\")\n",
    "   \n",
    "    val_auc, val_mrr, val_ndcg, val_ndcg10 = [np.mean(i) for i in list(zip(*np.array(all_rslt_ucb15)))]\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"ucb 1.5 auc: {val_auc:.4f}, mrr: {val_mrr:.4f}, ndcg5: {val_ndcg:.4f}, ndcg10: {val_ndcg10:.4f}\\n \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offline \n",
    "\n",
    "if offline_flag:\n",
    "    model = NRMS().to(device)\n",
    "    model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "    model.eval()\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('dropout'):\n",
    "            print(m)\n",
    "            m.train()\n",
    "\n",
    "    y_scores = defaultdict(list)\n",
    "    y_trues = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in tqdm(range(eva_times)):\n",
    "            test_news_dataset = NewsDataset(test_news_index)\n",
    "            news_dl = DataLoader(test_news_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(test_sam, news_vecs, test_nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=1024, shuffle=False, num_workers=0)\n",
    "            for his_tsp in tqdm(user_dl):\n",
    "                his, _ = his_tsp\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            for i in tqdm(range(len(valid_sam))):\n",
    "                poss, negs, _, _, _ = valid_sam[i]\n",
    "                user_vec = user_vecs[i]\n",
    "                y_true = [1] * len(poss) + [0] * len(negs)\n",
    "                news_ids = [nid2index[i] for i in poss + negs]\n",
    "                news_vec = news_vecs[news_ids]\n",
    "                y_score = np.multiply(news_vec, user_vec)\n",
    "                y_score = np.sum(y_score, axis=1)\n",
    "                \n",
    "                y_scores[i].append(y_score)\n",
    "                y_trues[i] = y_true\n",
    "\n",
    "    with open(model_path/f'{name}.txt', 'a') as f:\n",
    "        f.write(f\"offline eva with eva : {eva_times} times\\n\")\n",
    "    print_eva_metric(y_scores, y_trues)\n",
    "\n",
    "    # test_auc, test_mrr, test_ndcg, test_ndcg10 = [np.mean(i) for i in list(zip(*test_scores))]\n",
    "    # print(f\"[{i}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\")\n",
    "\n",
    "# with open(model_path/ f'{name}.txt', 'a') as f:\n",
    "#         f.write(f\"[{time}] time test auc: {test_auc:.4f}, mrr: {test_mrr:.4f}, ndcg5: {test_ndcg:.4f}, ndcg10: {test_ndcg10:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_trainable_samples(samples):\n",
    "    tr_samples = []\n",
    "    for l in samples:\n",
    "        pos_imp, neg_imp, his, uid, tsp = l    \n",
    "        for pos in list(pos_imp):\n",
    "            tr_samples.append([pos, neg_imp, his, uid, tsp])\n",
    "    return tr_samples\n",
    "\n",
    "\n",
    "\n",
    "def finetune(model, ft_sam, nid2index, news_index, batch_size):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    ft_sam = construct_trainable_samples(ft_sam)\n",
    "    ft_ds = TrainDataset(ft_sam, nid2index, news_index)\n",
    "    ft_dl = DataLoader(ft_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    for ep in range(epoch):\n",
    "        loss = 0\n",
    "        accuary = 0.0\n",
    "        model.train()\n",
    "        ft_loader = tqdm(ft_dl)\n",
    "        for cnt, batch_sample in enumerate(ft_loader):\n",
    "            candidate_news_index, his_index, label = batch_sample\n",
    "            sample_num = candidate_news_index.shape[0]\n",
    "            candidate_news_index = candidate_news_index.to(device)\n",
    "            his_index = his_index.to(device)\n",
    "            label = label.to(device)\n",
    "            bz_loss, y_hat = model(candidate_news_index, his_index, label)\n",
    "\n",
    "            loss += bz_loss.detach().cpu().numpy()\n",
    "            optimizer.zero_grad()\n",
    "            bz_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if cnt % 10 == 0:\n",
    "                ft_loader.set_description(f\"[{cnt}]steps loss: {loss / (cnt+1):.4f} \")\n",
    "                ft_loader.refresh() \n",
    "\n",
    "    return model \n",
    "\n",
    "def eva_batch(model, droupout_flag, batch_news_index, batch_sam, batch_nid2index, y_scores, y_trues, ucbs, batch_size, batch_id):\n",
    "    model.eval()\n",
    "    if droupout_flag:\n",
    "        for m in model.modules():\n",
    "            if m.__class__.__name__.startswith('dropout'):\n",
    "                print(m)\n",
    "                m.train()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(eva_times)):\n",
    "            batch_news_dataset = NewsDataset(batch_news_index)\n",
    "            news_dl = DataLoader(batch_news_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            news_vecs = []\n",
    "            for news in tqdm(news_dl):\n",
    "                news = news.to(device)\n",
    "                news_vec = model.text_encoder(news).detach().cpu().numpy()\n",
    "                news_vecs.append(news_vec)\n",
    "            news_vecs = np.concatenate(news_vecs)\n",
    "\n",
    "            user_dataset = UserDataset(batch_sam, news_vecs, batch_nid2index)\n",
    "            user_vecs = []\n",
    "            user_dl = DataLoader(user_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "            \n",
    "\n",
    "            for his_tsp in tqdm(user_dl):\n",
    "                his, tsp = his_tsp\n",
    "                batch_time = datetime.strptime(str(tsp[-1]), date_format_str)\n",
    "                his = his.to(device)\n",
    "                user_vec = model.user_encoder(his).detach().cpu().numpy()\n",
    "                user_vecs.append(user_vec)\n",
    "                # print(tsp)\n",
    "            user_vecs = np.concatenate(user_vecs)\n",
    "\n",
    "            start_id = batch_size * batch_id\n",
    "\n",
    "            for i in tqdm(range(len(batch_sam))):\n",
    "                poss, negs, _, _,_ = batch_sam[i]\n",
    "                user_vec = user_vecs[i]\n",
    "                y_true = [1] * len(poss) + [0] * len(negs)\n",
    "                news_ids = [nid2index[i] for i in poss + negs]\n",
    "                news_vec = news_vecs[news_ids]\n",
    "                y_score = np.multiply(news_vec, user_vec)\n",
    "                y_score = np.sum(y_score, axis=1)\n",
    "                \n",
    "                y_scores[start_id+i].append(y_score)\n",
    "                y_trues[start_id+i] = y_true\n",
    "                \n",
    "    return y_scores, y_trues, batch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# online \n",
    "\n",
    "if online_flag:\n",
    "\n",
    "    print('online eva')\n",
    "\n",
    "    model = NRMS().to(device)\n",
    "    model.load_state_dict(torch.load(model_path/f'{name}.pkl'))\n",
    "\n",
    "    y_scores = defaultdict(list)\n",
    "    y_trues = {}\n",
    "\n",
    "    update_time = None\n",
    "    update_batch = 0\n",
    "    batch_size = 1024\n",
    "    dropout_flag = True\n",
    "\n",
    "    n_batch = math.ceil(float(len(test_sam))/batch_size)\n",
    "\n",
    "    for i in range(n_batch):\n",
    "        upper_range = min(1024 * (i+1), len(test_sam))\n",
    "        batch_sam = test_sam[1024 * i: upper_range]\n",
    "\n",
    "        y_scores, y_trues, batch_time = eva_batch(model, dropout_flag, test_news_index, batch_sam, test_nid2index, y_scores, y_trues, batch_size, i)\n",
    "        \n",
    "        num_sample = len(y_scores)\n",
    "        with open(model_path/f'{name}.txt', 'a') as f:\n",
    "            f.write(f\"online eva on batch : {i} with {num_sample} samples in current batch, up to index {upper_range}\\n\")\n",
    "        print_eva_metric(y_scores, y_trues)\n",
    "    \n",
    "        if update_time is None:\n",
    "            update_time = batch_time\n",
    "            print('init update time: ', update_time)\n",
    "        if (batch_time- update_time).total_seconds() > 3600:\n",
    "\n",
    "            ft_sam = test_sam[1024 * update_batch: upper_range]\n",
    "            if upper_range - 1024 * update_batch > 512:\n",
    "                print('finetune with: '  + str(1024 * update_batch) + ' ~ ' + str(upper_range))\n",
    "                model = finetune(model=model, ft_sam=ft_sam, nid2index=test_nid2index, news_index=test_news_index, batch_size=32)\n",
    "\n",
    "                update_time = batch_time\n",
    "                update_batch = i + 1\n",
    "                print('update before: ', update_time)\n",
    "            else: \n",
    "                print('no finetune due to insufficient samples: ', str(upper_range - 1024 * update_batch))\n",
    "\n",
    "    torch.save(model.state_dict(), model_path/f'{name}_finetune.pkl')\n",
    "# sys.stdout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandit Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 79.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.55it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 83.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init time:  2019-11-15 00:00:13\n",
      "finetune with: 0 ~ 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/95 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_his_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7c1e76c8c818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnews_ctr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_ctr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterval_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     lr = lr, epoch = epoch, name = name)\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcb_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_exper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_exper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_inference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epsilon_greedy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_para\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CB4Rec/policy.py\u001b[0m in \u001b[0;36mrun_exper\u001b[0;34m(self, test_sam, num_exper, n_inference, policy, policy_para)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mupper_range\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlower_range\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finetune with: '\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_range\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ~ '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_sam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mft_sam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                         \u001b[0mupdate_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CB4Rec/policy.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(self, ft_sam)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mft_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mcandidate_news_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhis_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0msample_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_news_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CB4Rec/dataloader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# nindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mcandidate_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnews_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_news\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mhis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnid2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_his_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mhis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnews_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_his_len' is not defined"
     ]
    }
   ],
   "source": [
    "for para in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    print(para)\n",
    "    cb_sim = CB_sim(model_path=model_path, simulator_path=model_path, out_path=model_path, device=device, news_index=test_news_index, nid2index=test_nid2index, embedding_matrix = embedding_matrix, \n",
    "    news_ctr = news_ctr, start_time = start_time, interval_time = interval_time,\n",
    "    lr = lr, epoch = epoch, name = name)\n",
    "    cb_sim.run_exper(test_sam=test_sam, num_exper=2, n_inference = 2, policy='epsilon_greedy', policy_para=para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exper, num_sam = cb_sim.rewards.shape\n",
    "cumu_regrets = np.zeros((num_exper, num_sam))\n",
    "for i in range(num_exper):\n",
    "    cumu_reward = 0\n",
    "    cumu_opt_reward = 0\n",
    "\n",
    "    for j in range(num_sam):\n",
    "        cumu_reward += cb_sim.rewards[i,j]\n",
    "        cumu_opt_reward += cb_sim.opt_rewards[i,j]\n",
    "        cumu_regrets[i,j] = (cumu_opt_reward - cumu_reward)/(j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_sam), cumu_regrets.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cb_sim.rewards.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cb_sim.opt_rewards.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
